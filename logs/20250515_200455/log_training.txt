2025-05-15 20:04:55 1. Parse Arguments
2025-05-15 20:04:55 Namespace(dataset='NYC', seed=2023, distance_threshold=2.5, num_epochs=30, batch_size=200, emb_dim=128, lr=0.001, decay=0.0005, dropout=0.3, deviceID=0, lambda_cl=0.1, num_mv_layers=3, num_geo_layers=3, num_di_layers=3, temperature=0.1, keep_rate=1, keep_rate_poi=1, lr_scheduler_factor=0.1, save_dir='logs')
2025-05-15 20:04:55 device: cuda:0
2025-05-15 20:04:55 2. Load Dataset
2025-05-15 20:05:02 3. Construct DataLoader
2025-05-15 20:05:02 4. Load Model
2025-05-15 20:05:02 5. Start Training
2025-05-15 20:05:02 ================= Epoch 0/30 =================
2025-05-15 20:05:02 Train. Batch 0/5
2025-05-15 20:05:02 Train. loss_rec: 7.8237; loss_cl_pois: 2.4395; loss_cl_users: 0.5387; loss: 8.1215
2025-05-15 20:05:02 Train. Batch 1/5
2025-05-15 20:05:02 Train. loss_rec: 7.8004; loss_cl_pois: 2.3936; loss_cl_users: 0.3491; loss: 8.0747
2025-05-15 20:05:03 Train. Batch 2/5
2025-05-15 20:05:03 Train. loss_rec: 7.7709; loss_cl_pois: 2.3969; loss_cl_users: 0.3290; loss: 8.0435
2025-05-15 20:05:03 Train. Batch 3/5
2025-05-15 20:05:03 Train. loss_rec: 7.6701; loss_cl_pois: 2.4063; loss_cl_users: 0.3484; loss: 7.9456
2025-05-15 20:05:03 Train. Batch 4/5
2025-05-15 20:05:03 Train. loss_rec: 7.6491; loss_cl_pois: 2.4140; loss_cl_users: 0.0548; loss: 7.8960
2025-05-15 20:05:03 Training finishes at this epoch. It takes 0.00906296968460083 min
2025-05-15 20:05:03 Training loss: 8.0162
2025-05-15 20:05:03 Training Epoch 0/30 results:
2025-05-15 20:05:03 Recall@1: 0.0468
2025-05-15 20:05:03 NDCG@1: 0.0468
2025-05-15 20:05:03 Recall@5: 0.1691
2025-05-15 20:05:03 NDCG@5: 0.1080
2025-05-15 20:05:03 Recall@10: 0.2438
2025-05-15 20:05:03 NDCG@10: 0.1323
2025-05-15 20:05:03 Recall@20: 0.2995
2025-05-15 20:05:03 NDCG@20: 0.1466
2025-05-15 20:05:03 

2025-05-15 20:05:03 Testing
2025-05-15 20:05:03 Test. Batch 0/5
2025-05-15 20:05:03 Test. loss_rec: 7.5096; loss_cl_pois: 2.9252; loss_cl_users: 0.3569; loss: 7.8378
2025-05-15 20:05:03 Test. Batch 1/5
2025-05-15 20:05:03 Test. loss_rec: 7.5607; loss_cl_pois: 2.9214; loss_cl_users: 0.3485; loss: 7.8877
2025-05-15 20:05:03 Test. Batch 2/5
2025-05-15 20:05:03 Test. loss_rec: 7.5019; loss_cl_pois: 2.9255; loss_cl_users: 0.3557; loss: 7.8301
2025-05-15 20:05:03 Test. Batch 3/5
2025-05-15 20:05:03 Test. loss_rec: 7.5194; loss_cl_pois: 2.9113; loss_cl_users: 0.3227; loss: 7.8428
2025-05-15 20:05:03 Test. Batch 4/5
2025-05-15 20:05:03 Test. loss_rec: 7.4198; loss_cl_pois: 2.9255; loss_cl_users: 0.0415; loss: 7.7165
2025-05-15 20:05:03 Testing finishes
2025-05-15 20:05:03 Testing loss: 7.822977828979492
2025-05-15 20:05:03 Testing results:
2025-05-15 20:05:03 Recall@1: 0.1093
2025-05-15 20:05:03 NDCG@1: 0.1093
2025-05-15 20:05:03 Recall@5: 0.2587
2025-05-15 20:05:03 NDCG@5: 0.1876
2025-05-15 20:05:03 Recall@10: 0.3146
2025-05-15 20:05:03 NDCG@10: 0.2062
2025-05-15 20:05:03 Recall@20: 0.3456
2025-05-15 20:05:03 NDCG@20: 0.2142
2025-05-15 20:05:03 Update test results and save model at epoch0
2025-05-15 20:05:03 ==================================


2025-05-15 20:05:03 ================= Epoch 1/30 =================
2025-05-15 20:05:03 Train. Batch 0/5
2025-05-15 20:05:03 Train. loss_rec: 6.9971; loss_cl_pois: 2.4138; loss_cl_users: 0.3158; loss: 7.2701
2025-05-15 20:05:03 Train. Batch 1/5
2025-05-15 20:05:03 Train. loss_rec: 6.9615; loss_cl_pois: 2.4181; loss_cl_users: 0.3299; loss: 7.2363
2025-05-15 20:05:03 Train. Batch 2/5
2025-05-15 20:05:03 Train. loss_rec: 6.7949; loss_cl_pois: 2.4225; loss_cl_users: 0.3332; loss: 7.0704
2025-05-15 20:05:03 Train. Batch 3/5
2025-05-15 20:05:03 Train. loss_rec: 6.8528; loss_cl_pois: 2.4114; loss_cl_users: 0.3119; loss: 7.1251
2025-05-15 20:05:03 Train. Batch 4/5
2025-05-15 20:05:03 Train. loss_rec: 6.8548; loss_cl_pois: 2.4134; loss_cl_users: 0.0444; loss: 7.1006
2025-05-15 20:05:03 Training finishes at this epoch. It takes 0.006058740615844727 min
2025-05-15 20:05:03 Training loss: 7.1605
2025-05-15 20:05:03 Training Epoch 1/30 results:
2025-05-15 20:05:03 Recall@1: 0.3345
2025-05-15 20:05:03 NDCG@1: 0.3345
2025-05-15 20:05:03 Recall@5: 0.5089
2025-05-15 20:05:03 NDCG@5: 0.4247
2025-05-15 20:05:03 Recall@10: 0.6203
2025-05-15 20:05:03 NDCG@10: 0.4613
2025-05-15 20:05:03 Recall@20: 0.7171
2025-05-15 20:05:03 NDCG@20: 0.4856
2025-05-15 20:05:03 

2025-05-15 20:05:03 Testing
2025-05-15 20:05:03 Test. Batch 0/5
2025-05-15 20:05:03 Test. loss_rec: 7.3275; loss_cl_pois: 2.9185; loss_cl_users: 0.3048; loss: 7.6498
2025-05-15 20:05:03 Test. Batch 1/5
2025-05-15 20:05:03 Test. loss_rec: 7.3689; loss_cl_pois: 2.9174; loss_cl_users: 0.3281; loss: 7.6934
2025-05-15 20:05:03 Test. Batch 2/5
2025-05-15 20:05:03 Test. loss_rec: 7.5091; loss_cl_pois: 2.9135; loss_cl_users: 0.3278; loss: 7.8332
2025-05-15 20:05:04 Test. Batch 3/5
2025-05-15 20:05:04 Test. loss_rec: 7.3457; loss_cl_pois: 2.9131; loss_cl_users: 0.3609; loss: 7.6731
2025-05-15 20:05:04 Test. Batch 4/5
2025-05-15 20:05:04 Test. loss_rec: 7.0931; loss_cl_pois: 2.9208; loss_cl_users: 0.0637; loss: 7.3915
2025-05-15 20:05:04 Testing finishes
2025-05-15 20:05:04 Testing loss: 7.648202419281006
2025-05-15 20:05:04 Testing results:
2025-05-15 20:05:04 Recall@1: 0.1243
2025-05-15 20:05:04 NDCG@1: 0.1243
2025-05-15 20:05:04 Recall@5: 0.2924
2025-05-15 20:05:04 NDCG@5: 0.2108
2025-05-15 20:05:04 Recall@10: 0.3959
2025-05-15 20:05:04 NDCG@10: 0.2445
2025-05-15 20:05:04 Recall@20: 0.4368
2025-05-15 20:05:04 NDCG@20: 0.2550
2025-05-15 20:05:04 Update test results and save model at epoch1
2025-05-15 20:05:04 ==================================


2025-05-15 20:05:04 ================= Epoch 2/30 =================
2025-05-15 20:05:04 Train. Batch 0/5
2025-05-15 20:05:04 Train. loss_rec: 6.4115; loss_cl_pois: 2.4114; loss_cl_users: 0.2968; loss: 6.6823
2025-05-15 20:05:04 Train. Batch 1/5
2025-05-15 20:05:04 Train. loss_rec: 6.3589; loss_cl_pois: 2.4095; loss_cl_users: 0.3264; loss: 6.6325
2025-05-15 20:05:04 Train. Batch 2/5
2025-05-15 20:05:04 Train. loss_rec: 6.2482; loss_cl_pois: 2.4156; loss_cl_users: 0.3018; loss: 6.5199
2025-05-15 20:05:04 Train. Batch 3/5
2025-05-15 20:05:04 Train. loss_rec: 6.1682; loss_cl_pois: 2.4265; loss_cl_users: 0.3084; loss: 6.4417
2025-05-15 20:05:04 Train. Batch 4/5
2025-05-15 20:05:04 Train. loss_rec: 6.0853; loss_cl_pois: 2.4155; loss_cl_users: 0.0438; loss: 6.3312
2025-05-15 20:05:04 Training finishes at this epoch. It takes 0.0057001868883768715 min
2025-05-15 20:05:04 Training loss: 6.5215
2025-05-15 20:05:04 Training Epoch 2/30 results:
2025-05-15 20:05:04 Recall@1: 0.6408
2025-05-15 20:05:04 NDCG@1: 0.6408
2025-05-15 20:05:04 Recall@5: 0.8294
2025-05-15 20:05:04 NDCG@5: 0.7379
2025-05-15 20:05:04 Recall@10: 0.9192
2025-05-15 20:05:04 NDCG@10: 0.7673
2025-05-15 20:05:04 Recall@20: 0.9402
2025-05-15 20:05:04 NDCG@20: 0.7727
2025-05-15 20:05:04 

2025-05-15 20:05:04 Testing
2025-05-15 20:05:04 Test. Batch 0/5
2025-05-15 20:05:04 Test. loss_rec: 7.3114; loss_cl_pois: 2.9242; loss_cl_users: 0.3103; loss: 7.6349
2025-05-15 20:05:04 Test. Batch 1/5
2025-05-15 20:05:04 Test. loss_rec: 7.2317; loss_cl_pois: 2.9183; loss_cl_users: 0.3279; loss: 7.5563
2025-05-15 20:05:04 Test. Batch 2/5
2025-05-15 20:05:04 Test. loss_rec: 7.2179; loss_cl_pois: 2.9154; loss_cl_users: 0.3411; loss: 7.5436
2025-05-15 20:05:04 Test. Batch 3/5
2025-05-15 20:05:04 Test. loss_rec: 7.2843; loss_cl_pois: 2.9192; loss_cl_users: 0.3786; loss: 7.6140
2025-05-15 20:05:04 Test. Batch 4/5
2025-05-15 20:05:04 Test. loss_rec: 7.2182; loss_cl_pois: 2.9173; loss_cl_users: 0.0674; loss: 7.5167
2025-05-15 20:05:04 Testing finishes
2025-05-15 20:05:04 Testing loss: 7.573100280761719
2025-05-15 20:05:04 Testing results:
2025-05-15 20:05:04 Recall@1: 0.1473
2025-05-15 20:05:04 NDCG@1: 0.1473
2025-05-15 20:05:04 Recall@5: 0.3178
2025-05-15 20:05:04 NDCG@5: 0.2365
2025-05-15 20:05:04 Recall@10: 0.4204
2025-05-15 20:05:04 NDCG@10: 0.2708
2025-05-15 20:05:04 Recall@20: 0.4422
2025-05-15 20:05:04 NDCG@20: 0.2762
2025-05-15 20:05:04 Update test results and save model at epoch2
2025-05-15 20:05:04 ==================================


2025-05-15 20:05:04 ================= Epoch 3/30 =================
2025-05-15 20:05:04 Train. Batch 0/5
2025-05-15 20:05:04 Train. loss_rec: 5.9497; loss_cl_pois: 2.4205; loss_cl_users: 0.2882; loss: 6.2205
2025-05-15 20:05:04 Train. Batch 1/5
2025-05-15 20:05:04 Train. loss_rec: 5.8638; loss_cl_pois: 2.4180; loss_cl_users: 0.3204; loss: 6.1376
2025-05-15 20:05:04 Train. Batch 2/5
2025-05-15 20:05:04 Train. loss_rec: 5.7248; loss_cl_pois: 2.4330; loss_cl_users: 0.3281; loss: 6.0009
2025-05-15 20:05:04 Train. Batch 3/5
2025-05-15 20:05:04 Train. loss_rec: 5.6951; loss_cl_pois: 2.4343; loss_cl_users: 0.2945; loss: 5.9680
2025-05-15 20:05:05 Train. Batch 4/5
2025-05-15 20:05:05 Train. loss_rec: 5.5524; loss_cl_pois: 2.4351; loss_cl_users: 0.0620; loss: 5.8021
2025-05-15 20:05:05 Training finishes at this epoch. It takes 0.0053542216618855795 min
2025-05-15 20:05:05 Training loss: 6.0258
2025-05-15 20:05:05 Training Epoch 3/30 results:
2025-05-15 20:05:05 Recall@1: 0.8522
2025-05-15 20:05:05 NDCG@1: 0.8522
2025-05-15 20:05:05 Recall@5: 0.9610
2025-05-15 20:05:05 NDCG@5: 0.9107
2025-05-15 20:05:05 Recall@10: 0.9880
2025-05-15 20:05:05 NDCG@10: 0.9196
2025-05-15 20:05:05 Recall@20: 0.9950
2025-05-15 20:05:05 NDCG@20: 0.9215
2025-05-15 20:05:05 

2025-05-15 20:05:05 Testing
2025-05-15 20:05:05 Test. Batch 0/5
2025-05-15 20:05:05 Test. loss_rec: 7.1257; loss_cl_pois: 2.9310; loss_cl_users: 0.3616; loss: 7.4550
2025-05-15 20:05:05 Test. Batch 1/5
2025-05-15 20:05:05 Test. loss_rec: 7.1752; loss_cl_pois: 2.9396; loss_cl_users: 0.3195; loss: 7.5011
2025-05-15 20:05:05 Test. Batch 2/5
2025-05-15 20:05:05 Test. loss_rec: 7.1007; loss_cl_pois: 2.9337; loss_cl_users: 0.3663; loss: 7.4307
2025-05-15 20:05:05 Test. Batch 3/5
2025-05-15 20:05:05 Test. loss_rec: 7.2915; loss_cl_pois: 2.9428; loss_cl_users: 0.3273; loss: 7.6186
2025-05-15 20:05:05 Test. Batch 4/5
2025-05-15 20:05:05 Test. loss_rec: 6.9045; loss_cl_pois: 2.9336; loss_cl_users: 0.0735; loss: 7.2053
2025-05-15 20:05:05 Testing finishes
2025-05-15 20:05:05 Testing loss: 7.442113018035888
2025-05-15 20:05:05 Testing results:
2025-05-15 20:05:05 Recall@1: 0.2088
2025-05-15 20:05:05 NDCG@1: 0.2088
2025-05-15 20:05:05 Recall@5: 0.3931
2025-05-15 20:05:05 NDCG@5: 0.3024
2025-05-15 20:05:05 Recall@10: 0.4518
2025-05-15 20:05:05 NDCG@10: 0.3218
2025-05-15 20:05:05 Recall@20: 0.4618
2025-05-15 20:05:05 NDCG@20: 0.3244
2025-05-15 20:05:05 Update test results and save model at epoch3
2025-05-15 20:05:05 ==================================


2025-05-15 20:05:05 ================= Epoch 4/30 =================
2025-05-15 20:05:05 Train. Batch 0/5
2025-05-15 20:05:05 Train. loss_rec: 5.5138; loss_cl_pois: 2.4363; loss_cl_users: 0.3309; loss: 5.7905
2025-05-15 20:05:05 Train. Batch 1/5
2025-05-15 20:05:05 Train. loss_rec: 5.4563; loss_cl_pois: 2.4358; loss_cl_users: 0.2960; loss: 5.7295
2025-05-15 20:05:05 Train. Batch 2/5
2025-05-15 20:05:05 Train. loss_rec: 5.3365; loss_cl_pois: 2.4367; loss_cl_users: 0.3316; loss: 5.6133
2025-05-15 20:05:05 Train. Batch 3/5
2025-05-15 20:05:05 Train. loss_rec: 5.3497; loss_cl_pois: 2.4456; loss_cl_users: 0.3316; loss: 5.6274
2025-05-15 20:05:05 Train. Batch 4/5
2025-05-15 20:05:05 Train. loss_rec: 5.3671; loss_cl_pois: 2.4325; loss_cl_users: 0.0434; loss: 5.6147
2025-05-15 20:05:05 Training finishes at this epoch. It takes 0.00530314048131307 min
2025-05-15 20:05:05 Training loss: 5.6751
2025-05-15 20:05:05 Training Epoch 4/30 results:
2025-05-15 20:05:05 Recall@1: 0.9272
2025-05-15 20:05:05 NDCG@1: 0.9272
2025-05-15 20:05:05 Recall@5: 0.9930
2025-05-15 20:05:05 NDCG@5: 0.9634
2025-05-15 20:05:05 Recall@10: 0.9990
2025-05-15 20:05:05 NDCG@10: 0.9655
2025-05-15 20:05:05 Recall@20: 1.0000
2025-05-15 20:05:05 NDCG@20: 0.9657
2025-05-15 20:05:05 

2025-05-15 20:05:05 Testing
2025-05-15 20:05:05 Test. Batch 0/5
2025-05-15 20:05:05 Test. loss_rec: 6.9659; loss_cl_pois: 2.9385; loss_cl_users: 0.3417; loss: 7.2939
2025-05-15 20:05:05 Test. Batch 1/5
2025-05-15 20:05:05 Test. loss_rec: 7.1879; loss_cl_pois: 2.9433; loss_cl_users: 0.3464; loss: 7.5169
2025-05-15 20:05:05 Test. Batch 2/5
2025-05-15 20:05:05 Test. loss_rec: 7.1267; loss_cl_pois: 2.9383; loss_cl_users: 0.3935; loss: 7.4599
2025-05-15 20:05:05 Test. Batch 3/5
2025-05-15 20:05:05 Test. loss_rec: 7.0881; loss_cl_pois: 2.9361; loss_cl_users: 0.3313; loss: 7.4149
2025-05-15 20:05:05 Test. Batch 4/5
2025-05-15 20:05:05 Test. loss_rec: 7.0411; loss_cl_pois: 2.9450; loss_cl_users: 0.0579; loss: 7.3414
2025-05-15 20:05:05 Testing finishes
2025-05-15 20:05:05 Testing loss: 7.405392646789551
2025-05-15 20:05:05 Testing results:
2025-05-15 20:05:05 Recall@1: 0.2213
2025-05-15 20:05:05 NDCG@1: 0.2213
2025-05-15 20:05:05 Recall@5: 0.3875
2025-05-15 20:05:05 NDCG@5: 0.3071
2025-05-15 20:05:05 Recall@10: 0.4331
2025-05-15 20:05:05 NDCG@10: 0.3225
2025-05-15 20:05:05 Recall@20: 0.4590
2025-05-15 20:05:05 NDCG@20: 0.3290
2025-05-15 20:05:05 ==================================


2025-05-15 20:05:05 ================= Epoch 5/30 =================
2025-05-15 20:05:05 Train. Batch 0/5
2025-05-15 20:05:05 Train. loss_rec: 5.1982; loss_cl_pois: 2.4380; loss_cl_users: 0.3210; loss: 5.4741
2025-05-15 20:05:05 Train. Batch 1/5
2025-05-15 20:05:05 Train. loss_rec: 5.1097; loss_cl_pois: 2.4480; loss_cl_users: 0.3461; loss: 5.3891
2025-05-15 20:05:06 Train. Batch 2/5
2025-05-15 20:05:06 Train. loss_rec: 5.0586; loss_cl_pois: 2.4340; loss_cl_users: 0.3036; loss: 5.3323
2025-05-15 20:05:06 Train. Batch 3/5
2025-05-15 20:05:06 Train. loss_rec: 5.0194; loss_cl_pois: 2.4370; loss_cl_users: 0.3077; loss: 5.2939
2025-05-15 20:05:06 Train. Batch 4/5
2025-05-15 20:05:06 Train. loss_rec: 5.0536; loss_cl_pois: 2.4397; loss_cl_users: 0.0487; loss: 5.3024
2025-05-15 20:05:06 Training finishes at this epoch. It takes 0.005306220054626465 min
2025-05-15 20:05:06 Training loss: 5.3584
2025-05-15 20:05:06 Training Epoch 5/30 results:
2025-05-15 20:05:06 Recall@1: 0.9790
2025-05-15 20:05:06 NDCG@1: 0.9790
2025-05-15 20:05:06 Recall@5: 0.9980
2025-05-15 20:05:06 NDCG@5: 0.9898
2025-05-15 20:05:06 Recall@10: 1.0000
2025-05-15 20:05:06 NDCG@10: 0.9905
2025-05-15 20:05:06 Recall@20: 1.0000
2025-05-15 20:05:06 NDCG@20: 0.9905
2025-05-15 20:05:06 

2025-05-15 20:05:06 Testing
2025-05-15 20:05:06 Test. Batch 0/5
2025-05-15 20:05:06 Test. loss_rec: 6.9650; loss_cl_pois: 2.9317; loss_cl_users: 0.3794; loss: 7.2961
2025-05-15 20:05:06 Test. Batch 1/5
2025-05-15 20:05:06 Test. loss_rec: 7.1050; loss_cl_pois: 2.9327; loss_cl_users: 0.3073; loss: 7.4290
2025-05-15 20:05:06 Test. Batch 2/5
2025-05-15 20:05:06 Test. loss_rec: 6.9432; loss_cl_pois: 2.9397; loss_cl_users: 0.3536; loss: 7.2725
2025-05-15 20:05:06 Test. Batch 3/5
2025-05-15 20:05:06 Test. loss_rec: 7.1389; loss_cl_pois: 2.9390; loss_cl_users: 0.3804; loss: 7.4709
2025-05-15 20:05:06 Test. Batch 4/5
2025-05-15 20:05:06 Test. loss_rec: 6.8235; loss_cl_pois: 2.9320; loss_cl_users: 0.0469; loss: 7.1214
2025-05-15 20:05:06 Testing finishes
2025-05-15 20:05:06 Testing loss: 7.317986297607422
2025-05-15 20:05:06 Testing results:
2025-05-15 20:05:06 Recall@1: 0.2755
2025-05-15 20:05:06 NDCG@1: 0.2755
2025-05-15 20:05:06 Recall@5: 0.4032
2025-05-15 20:05:06 NDCG@5: 0.3425
2025-05-15 20:05:06 Recall@10: 0.4390
2025-05-15 20:05:06 NDCG@10: 0.3544
2025-05-15 20:05:06 Recall@20: 0.4619
2025-05-15 20:05:06 NDCG@20: 0.3601
2025-05-15 20:05:06 Update test results and save model at epoch5
2025-05-15 20:05:06 ==================================


2025-05-15 20:05:06 ================= Epoch 6/30 =================
2025-05-15 20:05:06 Train. Batch 0/5
2025-05-15 20:05:06 Train. loss_rec: 4.8949; loss_cl_pois: 2.4377; loss_cl_users: 0.2697; loss: 5.1656
2025-05-15 20:05:06 Train. Batch 1/5
2025-05-15 20:05:06 Train. loss_rec: 4.8405; loss_cl_pois: 2.4480; loss_cl_users: 0.3795; loss: 5.1232
2025-05-15 20:05:06 Train. Batch 2/5
2025-05-15 20:05:06 Train. loss_rec: 4.8104; loss_cl_pois: 2.4331; loss_cl_users: 0.3275; loss: 5.0864
2025-05-15 20:05:06 Train. Batch 3/5
2025-05-15 20:05:06 Train. loss_rec: 4.8204; loss_cl_pois: 2.4477; loss_cl_users: 0.3326; loss: 5.0984
2025-05-15 20:05:06 Train. Batch 4/5
2025-05-15 20:05:06 Train. loss_rec: 4.8355; loss_cl_pois: 2.4471; loss_cl_users: 0.0680; loss: 5.0870
2025-05-15 20:05:06 Training finishes at this epoch. It takes 0.00522768497467041 min
2025-05-15 20:05:06 Training loss: 5.1121
2025-05-15 20:05:06 Training Epoch 6/30 results:
2025-05-15 20:05:06 Recall@1: 0.9900
2025-05-15 20:05:06 NDCG@1: 0.9900
2025-05-15 20:05:06 Recall@5: 1.0000
2025-05-15 20:05:06 NDCG@5: 0.9957
2025-05-15 20:05:06 Recall@10: 1.0000
2025-05-15 20:05:06 NDCG@10: 0.9957
2025-05-15 20:05:06 Recall@20: 1.0000
2025-05-15 20:05:06 NDCG@20: 0.9957
2025-05-15 20:05:06 

2025-05-15 20:05:06 Testing
2025-05-15 20:05:06 Test. Batch 0/5
2025-05-15 20:05:06 Test. loss_rec: 6.8644; loss_cl_pois: 2.9330; loss_cl_users: 0.3593; loss: 7.1936
2025-05-15 20:05:06 Test. Batch 1/5
2025-05-15 20:05:06 Test. loss_rec: 6.9616; loss_cl_pois: 2.9478; loss_cl_users: 0.3913; loss: 7.2955
2025-05-15 20:05:06 Test. Batch 2/5
2025-05-15 20:05:06 Test. loss_rec: 6.9618; loss_cl_pois: 2.9402; loss_cl_users: 0.3705; loss: 7.2929
2025-05-15 20:05:06 Test. Batch 3/5
2025-05-15 20:05:06 Test. loss_rec: 7.2046; loss_cl_pois: 2.9350; loss_cl_users: 0.3449; loss: 7.5326
2025-05-15 20:05:06 Test. Batch 4/5
2025-05-15 20:05:06 Test. loss_rec: 6.5162; loss_cl_pois: 2.9354; loss_cl_users: 0.0536; loss: 6.8151
2025-05-15 20:05:06 Testing finishes
2025-05-15 20:05:06 Testing loss: 7.225936031341552
2025-05-15 20:05:06 Testing results:
2025-05-15 20:05:06 Recall@1: 0.2776
2025-05-15 20:05:06 NDCG@1: 0.2776
2025-05-15 20:05:06 Recall@5: 0.4179
2025-05-15 20:05:06 NDCG@5: 0.3531
2025-05-15 20:05:06 Recall@10: 0.4586
2025-05-15 20:05:06 NDCG@10: 0.3664
2025-05-15 20:05:06 Recall@20: 0.4755
2025-05-15 20:05:06 NDCG@20: 0.3707
2025-05-15 20:05:06 Update test results and save model at epoch6
2025-05-15 20:05:06 ==================================


2025-05-15 20:05:06 ================= Epoch 7/30 =================
2025-05-15 20:05:07 Train. Batch 0/5
2025-05-15 20:05:07 Train. loss_rec: 4.7203; loss_cl_pois: 2.4440; loss_cl_users: 0.3623; loss: 5.0010
2025-05-15 20:05:07 Train. Batch 1/5
2025-05-15 20:05:07 Train. loss_rec: 4.6223; loss_cl_pois: 2.4536; loss_cl_users: 0.3578; loss: 4.9034
2025-05-15 20:05:07 Train. Batch 2/5
2025-05-15 20:05:07 Train. loss_rec: 4.6372; loss_cl_pois: 2.4418; loss_cl_users: 0.3528; loss: 4.9167
2025-05-15 20:05:07 Train. Batch 3/5
2025-05-15 20:05:07 Train. loss_rec: 4.6027; loss_cl_pois: 2.4334; loss_cl_users: 0.3742; loss: 4.8835
2025-05-15 20:05:07 Train. Batch 4/5
2025-05-15 20:05:07 Train. loss_rec: 4.5490; loss_cl_pois: 2.4336; loss_cl_users: 0.0471; loss: 4.7971
2025-05-15 20:05:07 Training finishes at this epoch. It takes 0.005288624763488769 min
2025-05-15 20:05:07 Training loss: 4.9003
2025-05-15 20:05:07 Training Epoch 7/30 results:
2025-05-15 20:05:07 Recall@1: 0.9921
2025-05-15 20:05:07 NDCG@1: 0.9921
2025-05-15 20:05:07 Recall@5: 1.0000
2025-05-15 20:05:07 NDCG@5: 0.9969
2025-05-15 20:05:07 Recall@10: 1.0000
2025-05-15 20:05:07 NDCG@10: 0.9969
2025-05-15 20:05:07 Recall@20: 1.0000
2025-05-15 20:05:07 NDCG@20: 0.9969
2025-05-15 20:05:07 

2025-05-15 20:05:07 Testing
2025-05-15 20:05:07 Test. Batch 0/5
2025-05-15 20:05:07 Test. loss_rec: 6.9661; loss_cl_pois: 2.9377; loss_cl_users: 0.3744; loss: 7.2973
2025-05-15 20:05:07 Test. Batch 1/5
2025-05-15 20:05:07 Test. loss_rec: 7.0429; loss_cl_pois: 2.9330; loss_cl_users: 0.3683; loss: 7.3731
2025-05-15 20:05:07 Test. Batch 2/5
2025-05-15 20:05:07 Test. loss_rec: 6.8414; loss_cl_pois: 2.9290; loss_cl_users: 0.3953; loss: 7.1738
2025-05-15 20:05:07 Test. Batch 3/5
2025-05-15 20:05:07 Test. loss_rec: 6.9399; loss_cl_pois: 2.9294; loss_cl_users: 0.3426; loss: 7.2671
2025-05-15 20:05:07 Test. Batch 4/5
2025-05-15 20:05:07 Test. loss_rec: 6.7970; loss_cl_pois: 2.9361; loss_cl_users: 0.0583; loss: 7.0965
2025-05-15 20:05:07 Testing finishes
2025-05-15 20:05:07 Testing loss: 7.24155559539795
2025-05-15 20:05:07 Testing results:
2025-05-15 20:05:07 Recall@1: 0.2748
2025-05-15 20:05:07 NDCG@1: 0.2748
2025-05-15 20:05:07 Recall@5: 0.3925
2025-05-15 20:05:07 NDCG@5: 0.3387
2025-05-15 20:05:07 Recall@10: 0.4351
2025-05-15 20:05:07 NDCG@10: 0.3529
2025-05-15 20:05:07 Recall@20: 0.4481
2025-05-15 20:05:07 NDCG@20: 0.3562
2025-05-15 20:05:07 ==================================


2025-05-15 20:05:07 ================= Epoch 8/30 =================
2025-05-15 20:05:07 Train. Batch 0/5
2025-05-15 20:05:07 Train. loss_rec: 4.5097; loss_cl_pois: 2.4358; loss_cl_users: 0.3423; loss: 4.7875
2025-05-15 20:05:07 Train. Batch 1/5
2025-05-15 20:05:07 Train. loss_rec: 4.4835; loss_cl_pois: 2.4282; loss_cl_users: 0.3890; loss: 4.7652
2025-05-15 20:05:07 Train. Batch 2/5
2025-05-15 20:05:07 Train. loss_rec: 4.4381; loss_cl_pois: 2.4261; loss_cl_users: 0.3469; loss: 4.7154
2025-05-15 20:05:07 Train. Batch 3/5
2025-05-15 20:05:07 Train. loss_rec: 4.4111; loss_cl_pois: 2.4352; loss_cl_users: 0.4037; loss: 4.6950
2025-05-15 20:05:07 Train. Batch 4/5
2025-05-15 20:05:07 Train. loss_rec: 4.4718; loss_cl_pois: 2.4309; loss_cl_users: 0.0515; loss: 4.7200
2025-05-15 20:05:07 Training finishes at this epoch. It takes 0.005254089832305908 min
2025-05-15 20:05:07 Training loss: 4.7366
2025-05-15 20:05:07 Training Epoch 8/30 results:
2025-05-15 20:05:07 Recall@1: 0.9990
2025-05-15 20:05:07 NDCG@1: 0.9990
2025-05-15 20:05:07 Recall@5: 1.0000
2025-05-15 20:05:07 NDCG@5: 0.9995
2025-05-15 20:05:07 Recall@10: 1.0000
2025-05-15 20:05:07 NDCG@10: 0.9995
2025-05-15 20:05:07 Recall@20: 1.0000
2025-05-15 20:05:07 NDCG@20: 0.9995
2025-05-15 20:05:07 

2025-05-15 20:05:07 Testing
2025-05-15 20:05:07 Test. Batch 0/5
2025-05-15 20:05:07 Test. loss_rec: 6.9010; loss_cl_pois: 2.9304; loss_cl_users: 0.3662; loss: 7.2307
2025-05-15 20:05:07 Test. Batch 1/5
2025-05-15 20:05:07 Test. loss_rec: 7.0496; loss_cl_pois: 2.9293; loss_cl_users: 0.3781; loss: 7.3803
2025-05-15 20:05:07 Test. Batch 2/5
2025-05-15 20:05:08 Test. loss_rec: 6.8639; loss_cl_pois: 2.9305; loss_cl_users: 0.4079; loss: 7.1978
2025-05-15 20:05:08 Test. Batch 3/5
2025-05-15 20:05:08 Test. loss_rec: 6.8447; loss_cl_pois: 2.9321; loss_cl_users: 0.3762; loss: 7.1755
2025-05-15 20:05:08 Test. Batch 4/5
2025-05-15 20:05:08 Test. loss_rec: 6.7559; loss_cl_pois: 2.9330; loss_cl_users: 0.0888; loss: 7.0581
2025-05-15 20:05:08 Testing finishes
2025-05-15 20:05:08 Testing loss: 7.208472537994385
2025-05-15 20:05:08 Testing results:
2025-05-15 20:05:08 Recall@1: 0.2935
2025-05-15 20:05:08 NDCG@1: 0.2935
2025-05-15 20:05:08 Recall@5: 0.3974
2025-05-15 20:05:08 NDCG@5: 0.3472
2025-05-15 20:05:08 Recall@10: 0.4302
2025-05-15 20:05:08 NDCG@10: 0.3581
2025-05-15 20:05:08 Recall@20: 0.4520
2025-05-15 20:05:08 NDCG@20: 0.3638
2025-05-15 20:05:08 ==================================


2025-05-15 20:05:08 ================= Epoch 9/30 =================
2025-05-15 20:05:08 Train. Batch 0/5
2025-05-15 20:05:08 Train. loss_rec: 4.3816; loss_cl_pois: 2.4434; loss_cl_users: 0.4365; loss: 4.6696
2025-05-15 20:05:08 Train. Batch 1/5
2025-05-15 20:05:08 Train. loss_rec: 4.3194; loss_cl_pois: 2.4471; loss_cl_users: 0.4200; loss: 4.6061
2025-05-15 20:05:08 Train. Batch 2/5
2025-05-15 20:05:08 Train. loss_rec: 4.2866; loss_cl_pois: 2.4424; loss_cl_users: 0.4044; loss: 4.5713
2025-05-15 20:05:08 Train. Batch 3/5
2025-05-15 20:05:08 Train. loss_rec: 4.2542; loss_cl_pois: 2.4199; loss_cl_users: 0.3646; loss: 4.5327
2025-05-15 20:05:08 Train. Batch 4/5
2025-05-15 20:05:08 Train. loss_rec: 4.2477; loss_cl_pois: 2.4257; loss_cl_users: 0.0462; loss: 4.4949
2025-05-15 20:05:08 Training finishes at this epoch. It takes 0.005282258987426758 min
2025-05-15 20:05:08 Training loss: 4.5749
2025-05-15 20:05:08 Training Epoch 9/30 results:
2025-05-15 20:05:08 Recall@1: 0.9990
2025-05-15 20:05:08 NDCG@1: 0.9990
2025-05-15 20:05:08 Recall@5: 1.0000
2025-05-15 20:05:08 NDCG@5: 0.9996
2025-05-15 20:05:08 Recall@10: 1.0000
2025-05-15 20:05:08 NDCG@10: 0.9996
2025-05-15 20:05:08 Recall@20: 1.0000
2025-05-15 20:05:08 NDCG@20: 0.9996
2025-05-15 20:05:08 

2025-05-15 20:05:08 Testing
2025-05-15 20:05:08 Test. Batch 0/5
2025-05-15 20:05:08 Test. loss_rec: 6.7540; loss_cl_pois: 2.9197; loss_cl_users: 0.4396; loss: 7.0899
2025-05-15 20:05:08 Test. Batch 1/5
2025-05-15 20:05:08 Test. loss_rec: 6.8419; loss_cl_pois: 2.9268; loss_cl_users: 0.4074; loss: 7.1753
2025-05-15 20:05:08 Test. Batch 2/5
2025-05-15 20:05:08 Test. loss_rec: 6.9943; loss_cl_pois: 2.9188; loss_cl_users: 0.3598; loss: 7.3221
2025-05-15 20:05:08 Test. Batch 3/5
2025-05-15 20:05:08 Test. loss_rec: 6.8001; loss_cl_pois: 2.9151; loss_cl_users: 0.3606; loss: 7.1277
2025-05-15 20:05:08 Test. Batch 4/5
2025-05-15 20:05:08 Test. loss_rec: 7.3752; loss_cl_pois: 2.9292; loss_cl_users: 0.0626; loss: 7.6744
2025-05-15 20:05:08 Testing finishes
2025-05-15 20:05:08 Testing loss: 7.277874374389649
2025-05-15 20:05:08 Testing results:
2025-05-15 20:05:08 Recall@1: 0.2582
2025-05-15 20:05:08 NDCG@1: 0.2582
2025-05-15 20:05:08 Recall@5: 0.3738
2025-05-15 20:05:08 NDCG@5: 0.3219
2025-05-15 20:05:08 Recall@10: 0.4048
2025-05-15 20:05:08 NDCG@10: 0.3324
2025-05-15 20:05:08 Recall@20: 0.4178
2025-05-15 20:05:08 NDCG@20: 0.3357
2025-05-15 20:05:08 ==================================


2025-05-15 20:05:08 ================= Epoch 10/30 =================
2025-05-15 20:05:08 Train. Batch 0/5
2025-05-15 20:05:08 Train. loss_rec: 4.2113; loss_cl_pois: 2.4236; loss_cl_users: 0.4093; loss: 4.4946
2025-05-15 20:05:08 Train. Batch 1/5
2025-05-15 20:05:08 Train. loss_rec: 4.1837; loss_cl_pois: 2.4301; loss_cl_users: 0.4543; loss: 4.4722
2025-05-15 20:05:08 Train. Batch 2/5
2025-05-15 20:05:08 Train. loss_rec: 4.1522; loss_cl_pois: 2.4215; loss_cl_users: 0.4212; loss: 4.4365
2025-05-15 20:05:08 Train. Batch 3/5
2025-05-15 20:05:08 Train. loss_rec: 4.1516; loss_cl_pois: 2.4144; loss_cl_users: 0.4287; loss: 4.4359
2025-05-15 20:05:08 Train. Batch 4/5
2025-05-15 20:05:08 Train. loss_rec: 4.1838; loss_cl_pois: 2.4272; loss_cl_users: 0.0569; loss: 4.4322
2025-05-15 20:05:08 Training finishes at this epoch. It takes 0.005268279711405436 min
2025-05-15 20:05:08 Training loss: 4.4543
2025-05-15 20:05:08 Training Epoch 10/30 results:
2025-05-15 20:05:08 Recall@1: 1.0000
2025-05-15 20:05:08 NDCG@1: 1.0000
2025-05-15 20:05:08 Recall@5: 1.0000
2025-05-15 20:05:08 NDCG@5: 1.0000
2025-05-15 20:05:08 Recall@10: 1.0000
2025-05-15 20:05:08 NDCG@10: 1.0000
2025-05-15 20:05:08 Recall@20: 1.0000
2025-05-15 20:05:08 NDCG@20: 1.0000
2025-05-15 20:05:08 

2025-05-15 20:05:08 Testing
2025-05-15 20:05:09 Test. Batch 0/5
2025-05-15 20:05:09 Test. loss_rec: 6.6758; loss_cl_pois: 2.9116; loss_cl_users: 0.4413; loss: 7.0111
2025-05-15 20:05:09 Test. Batch 1/5
2025-05-15 20:05:09 Test. loss_rec: 6.9897; loss_cl_pois: 2.9175; loss_cl_users: 0.3789; loss: 7.3194
2025-05-15 20:05:09 Test. Batch 2/5
2025-05-15 20:05:09 Test. loss_rec: 6.9146; loss_cl_pois: 2.9255; loss_cl_users: 0.4055; loss: 7.2477
2025-05-15 20:05:09 Test. Batch 3/5
2025-05-15 20:05:09 Test. loss_rec: 6.7971; loss_cl_pois: 2.9248; loss_cl_users: 0.3578; loss: 7.1253
2025-05-15 20:05:09 Test. Batch 4/5
2025-05-15 20:05:09 Test. loss_rec: 6.8302; loss_cl_pois: 2.9297; loss_cl_users: 0.0770; loss: 7.1308
2025-05-15 20:05:09 Testing finishes
2025-05-15 20:05:09 Testing loss: 7.1668556213378904
2025-05-15 20:05:09 Testing results:
2025-05-15 20:05:09 Recall@1: 0.2739
2025-05-15 20:05:09 NDCG@1: 0.2739
2025-05-15 20:05:09 Recall@5: 0.3984
2025-05-15 20:05:09 NDCG@5: 0.3416
2025-05-15 20:05:09 Recall@10: 0.4322
2025-05-15 20:05:09 NDCG@10: 0.3527
2025-05-15 20:05:09 Recall@20: 0.4501
2025-05-15 20:05:09 NDCG@20: 0.3572
2025-05-15 20:05:09 ==================================


2025-05-15 20:05:09 ================= Epoch 11/30 =================
2025-05-15 20:05:09 Train. Batch 0/5
2025-05-15 20:05:09 Train. loss_rec: 4.0688; loss_cl_pois: 2.4232; loss_cl_users: 0.4599; loss: 4.3571
2025-05-15 20:05:09 Train. Batch 1/5
2025-05-15 20:05:09 Train. loss_rec: 4.0683; loss_cl_pois: 2.4360; loss_cl_users: 0.4901; loss: 4.3609
2025-05-15 20:05:09 Train. Batch 2/5
2025-05-15 20:05:09 Train. loss_rec: 4.0462; loss_cl_pois: 2.4244; loss_cl_users: 0.5017; loss: 4.3388
2025-05-15 20:05:09 Train. Batch 3/5
2025-05-15 20:05:09 Train. loss_rec: 4.0455; loss_cl_pois: 2.4204; loss_cl_users: 0.4745; loss: 4.3350
2025-05-15 20:05:09 Train. Batch 4/5
2025-05-15 20:05:09 Train. loss_rec: 4.0106; loss_cl_pois: 2.4284; loss_cl_users: 0.0715; loss: 4.2606
2025-05-15 20:05:09 Training finishes at this epoch. It takes 0.0051615317662556965 min
2025-05-15 20:05:09 Training loss: 4.3305
2025-05-15 20:05:09 Training Epoch 11/30 results:
2025-05-15 20:05:09 Recall@1: 0.9990
2025-05-15 20:05:09 NDCG@1: 0.9990
2025-05-15 20:05:09 Recall@5: 1.0000
2025-05-15 20:05:09 NDCG@5: 0.9996
2025-05-15 20:05:09 Recall@10: 1.0000
2025-05-15 20:05:09 NDCG@10: 0.9996
2025-05-15 20:05:09 Recall@20: 1.0000
2025-05-15 20:05:09 NDCG@20: 0.9996
2025-05-15 20:05:09 

2025-05-15 20:05:09 Testing
2025-05-15 20:05:09 Test. Batch 0/5
2025-05-15 20:05:09 Test. loss_rec: 6.8070; loss_cl_pois: 2.9164; loss_cl_users: 0.4464; loss: 7.1433
2025-05-15 20:05:09 Test. Batch 1/5
2025-05-15 20:05:09 Test. loss_rec: 7.0108; loss_cl_pois: 2.9278; loss_cl_users: 0.3953; loss: 7.3432
2025-05-15 20:05:09 Test. Batch 2/5
2025-05-15 20:05:09 Test. loss_rec: 6.8278; loss_cl_pois: 2.9250; loss_cl_users: 0.4130; loss: 7.1617
2025-05-15 20:05:09 Test. Batch 3/5
2025-05-15 20:05:09 Test. loss_rec: 6.6038; loss_cl_pois: 2.9227; loss_cl_users: 0.4036; loss: 6.9364
2025-05-15 20:05:09 Test. Batch 4/5
2025-05-15 20:05:09 Test. loss_rec: 6.9503; loss_cl_pois: 2.9263; loss_cl_users: 0.0652; loss: 7.2494
2025-05-15 20:05:09 Testing finishes
2025-05-15 20:05:09 Testing loss: 7.166787815093994
2025-05-15 20:05:09 Testing results:
2025-05-15 20:05:09 Recall@1: 0.2769
2025-05-15 20:05:09 NDCG@1: 0.2769
2025-05-15 20:05:09 Recall@5: 0.3866
2025-05-15 20:05:09 NDCG@5: 0.3364
2025-05-15 20:05:09 Recall@10: 0.4156
2025-05-15 20:05:09 NDCG@10: 0.3460
2025-05-15 20:05:09 Recall@20: 0.4296
2025-05-15 20:05:09 NDCG@20: 0.3496
2025-05-15 20:05:09 ==================================


2025-05-15 20:05:09 ================= Epoch 12/30 =================
2025-05-15 20:05:09 Train. Batch 0/5
2025-05-15 20:05:09 Train. loss_rec: 3.9652; loss_cl_pois: 2.4251; loss_cl_users: 0.4772; loss: 4.2554
2025-05-15 20:05:09 Train. Batch 1/5
2025-05-15 20:05:09 Train. loss_rec: 3.9671; loss_cl_pois: 2.4225; loss_cl_users: 0.5125; loss: 4.2606
2025-05-15 20:05:09 Train. Batch 2/5
2025-05-15 20:05:09 Train. loss_rec: 3.9610; loss_cl_pois: 2.4281; loss_cl_users: 0.5997; loss: 4.2637
2025-05-15 20:05:10 Train. Batch 3/5
2025-05-15 20:05:10 Train. loss_rec: 3.9287; loss_cl_pois: 2.4320; loss_cl_users: 0.5369; loss: 4.2256
2025-05-15 20:05:10 Train. Batch 4/5
2025-05-15 20:05:10 Train. loss_rec: 3.9498; loss_cl_pois: 2.4163; loss_cl_users: 0.1229; loss: 4.2037
2025-05-15 20:05:10 Training finishes at this epoch. It takes 0.00522161324818929 min
2025-05-15 20:05:10 Training loss: 4.2418
2025-05-15 20:05:10 Training Epoch 12/30 results:
2025-05-15 20:05:10 Recall@1: 1.0000
2025-05-15 20:05:10 NDCG@1: 1.0000
2025-05-15 20:05:10 Recall@5: 1.0000
2025-05-15 20:05:10 NDCG@5: 1.0000
2025-05-15 20:05:10 Recall@10: 1.0000
2025-05-15 20:05:10 NDCG@10: 1.0000
2025-05-15 20:05:10 Recall@20: 1.0000
2025-05-15 20:05:10 NDCG@20: 1.0000
2025-05-15 20:05:10 

2025-05-15 20:05:10 Testing
2025-05-15 20:05:10 Test. Batch 0/5
2025-05-15 20:05:10 Test. loss_rec: 6.7395; loss_cl_pois: 2.9177; loss_cl_users: 0.4098; loss: 7.0722
2025-05-15 20:05:10 Test. Batch 1/5
2025-05-15 20:05:10 Test. loss_rec: 6.6397; loss_cl_pois: 2.9192; loss_cl_users: 0.4083; loss: 6.9725
2025-05-15 20:05:10 Test. Batch 2/5
2025-05-15 20:05:10 Test. loss_rec: 6.8790; loss_cl_pois: 2.9151; loss_cl_users: 0.4009; loss: 7.2106
2025-05-15 20:05:10 Test. Batch 3/5
2025-05-15 20:05:10 Test. loss_rec: 6.9377; loss_cl_pois: 2.9153; loss_cl_users: 0.4554; loss: 7.2748
2025-05-15 20:05:10 Test. Batch 4/5
2025-05-15 20:05:10 Test. loss_rec: 6.5534; loss_cl_pois: 2.9117; loss_cl_users: 0.0574; loss: 6.8503
2025-05-15 20:05:10 Testing finishes
2025-05-15 20:05:10 Testing loss: 7.0760674476623535
2025-05-15 20:05:10 Testing results:
2025-05-15 20:05:10 Recall@1: 0.2945
2025-05-15 20:05:10 NDCG@1: 0.2945
2025-05-15 20:05:10 Recall@5: 0.4071
2025-05-15 20:05:10 NDCG@5: 0.3551
2025-05-15 20:05:10 Recall@10: 0.4420
2025-05-15 20:05:10 NDCG@10: 0.3662
2025-05-15 20:05:10 Recall@20: 0.4520
2025-05-15 20:05:10 NDCG@20: 0.3687
2025-05-15 20:05:10 ==================================


2025-05-15 20:05:10 ================= Epoch 13/30 =================
2025-05-15 20:05:10 Train. Batch 0/5
2025-05-15 20:05:10 Train. loss_rec: 3.8760; loss_cl_pois: 2.4232; loss_cl_users: 0.5466; loss: 4.1730
2025-05-15 20:05:10 Train. Batch 1/5
2025-05-15 20:05:10 Train. loss_rec: 3.8688; loss_cl_pois: 2.4244; loss_cl_users: 0.4616; loss: 4.1574
2025-05-15 20:05:10 Train. Batch 2/5
2025-05-15 20:05:10 Train. loss_rec: 3.8438; loss_cl_pois: 2.4275; loss_cl_users: 0.6312; loss: 4.1497
2025-05-15 20:05:10 Train. Batch 3/5
2025-05-15 20:05:10 Train. loss_rec: 3.8357; loss_cl_pois: 2.4196; loss_cl_users: 0.5230; loss: 4.1299
2025-05-15 20:05:10 Train. Batch 4/5
2025-05-15 20:05:10 Train. loss_rec: 3.8451; loss_cl_pois: 2.4171; loss_cl_users: 0.1697; loss: 4.1038
2025-05-15 20:05:10 Training finishes at this epoch. It takes 0.005264572302500407 min
2025-05-15 20:05:10 Training loss: 4.1428
2025-05-15 20:05:10 Training Epoch 13/30 results:
2025-05-15 20:05:10 Recall@1: 1.0000
2025-05-15 20:05:10 NDCG@1: 1.0000
2025-05-15 20:05:10 Recall@5: 1.0000
2025-05-15 20:05:10 NDCG@5: 1.0000
2025-05-15 20:05:10 Recall@10: 1.0000
2025-05-15 20:05:10 NDCG@10: 1.0000
2025-05-15 20:05:10 Recall@20: 1.0000
2025-05-15 20:05:10 NDCG@20: 1.0000
2025-05-15 20:05:10 

2025-05-15 20:05:10 Testing
2025-05-15 20:05:10 Test. Batch 0/5
2025-05-15 20:05:10 Test. loss_rec: 6.7511; loss_cl_pois: 2.9257; loss_cl_users: 0.4605; loss: 7.0898
2025-05-15 20:05:10 Test. Batch 1/5
2025-05-15 20:05:10 Test. loss_rec: 6.7692; loss_cl_pois: 2.9252; loss_cl_users: 0.4273; loss: 7.1044
2025-05-15 20:05:10 Test. Batch 2/5
2025-05-15 20:05:10 Test. loss_rec: 6.6563; loss_cl_pois: 2.9236; loss_cl_users: 0.4294; loss: 6.9916
2025-05-15 20:05:10 Test. Batch 3/5
2025-05-15 20:05:10 Test. loss_rec: 6.9614; loss_cl_pois: 2.9303; loss_cl_users: 0.4209; loss: 7.2965
2025-05-15 20:05:10 Test. Batch 4/5
2025-05-15 20:05:10 Test. loss_rec: 6.3418; loss_cl_pois: 2.9197; loss_cl_users: 0.1487; loss: 6.6487
2025-05-15 20:05:10 Testing finishes
2025-05-15 20:05:10 Testing loss: 7.026187896728516
2025-05-15 20:05:10 Testing results:
2025-05-15 20:05:10 Recall@1: 0.2965
2025-05-15 20:05:10 NDCG@1: 0.2965
2025-05-15 20:05:10 Recall@5: 0.4061
2025-05-15 20:05:10 NDCG@5: 0.3550
2025-05-15 20:05:10 Recall@10: 0.4459
2025-05-15 20:05:10 NDCG@10: 0.3682
2025-05-15 20:05:10 Recall@20: 0.4589
2025-05-15 20:05:10 NDCG@20: 0.3715
2025-05-15 20:05:10 ==================================


2025-05-15 20:05:10 ================= Epoch 14/30 =================
2025-05-15 20:05:10 Train. Batch 0/5
2025-05-15 20:05:10 Train. loss_rec: 3.7889; loss_cl_pois: 2.4216; loss_cl_users: 0.5789; loss: 4.0889
2025-05-15 20:05:10 Train. Batch 1/5
2025-05-15 20:05:10 Train. loss_rec: 3.7741; loss_cl_pois: 2.4271; loss_cl_users: 0.6042; loss: 4.0772
2025-05-15 20:05:11 Train. Batch 2/5
2025-05-15 20:05:11 Train. loss_rec: 3.7491; loss_cl_pois: 2.4137; loss_cl_users: 0.5389; loss: 4.0444
2025-05-15 20:05:11 Train. Batch 3/5
2025-05-15 20:05:11 Train. loss_rec: 3.7620; loss_cl_pois: 2.4212; loss_cl_users: 0.6628; loss: 4.0704
2025-05-15 20:05:11 Train. Batch 4/5
2025-05-15 20:05:11 Train. loss_rec: 3.7281; loss_cl_pois: 2.4285; loss_cl_users: 0.1160; loss: 3.9826
2025-05-15 20:05:11 Training finishes at this epoch. It takes 0.005268573760986328 min
2025-05-15 20:05:11 Training loss: 4.0527
2025-05-15 20:05:11 Training Epoch 14/30 results:
2025-05-15 20:05:11 Recall@1: 1.0000
2025-05-15 20:05:11 NDCG@1: 1.0000
2025-05-15 20:05:11 Recall@5: 1.0000
2025-05-15 20:05:11 NDCG@5: 1.0000
2025-05-15 20:05:11 Recall@10: 1.0000
2025-05-15 20:05:11 NDCG@10: 1.0000
2025-05-15 20:05:11 Recall@20: 1.0000
2025-05-15 20:05:11 NDCG@20: 1.0000
2025-05-15 20:05:11 

2025-05-15 20:05:11 Testing
2025-05-15 20:05:11 Test. Batch 0/5
2025-05-15 20:05:11 Test. loss_rec: 6.7981; loss_cl_pois: 2.9204; loss_cl_users: 0.3921; loss: 7.1293
2025-05-15 20:05:11 Test. Batch 1/5
2025-05-15 20:05:11 Test. loss_rec: 6.5969; loss_cl_pois: 2.9190; loss_cl_users: 0.4496; loss: 6.9337
2025-05-15 20:05:11 Test. Batch 2/5
2025-05-15 20:05:11 Test. loss_rec: 6.7096; loss_cl_pois: 2.9296; loss_cl_users: 0.5089; loss: 7.0534
2025-05-15 20:05:11 Test. Batch 3/5
2025-05-15 20:05:11 Test. loss_rec: 6.8006; loss_cl_pois: 2.9361; loss_cl_users: 0.4281; loss: 7.1370
2025-05-15 20:05:11 Test. Batch 4/5
2025-05-15 20:05:11 Test. loss_rec: 7.0373; loss_cl_pois: 2.9221; loss_cl_users: 0.1004; loss: 7.3396
2025-05-15 20:05:11 Testing finishes
2025-05-15 20:05:11 Testing loss: 7.118625068664551
2025-05-15 20:05:11 Testing results:
2025-05-15 20:05:11 Recall@1: 0.2652
2025-05-15 20:05:11 NDCG@1: 0.2652
2025-05-15 20:05:11 Recall@5: 0.3758
2025-05-15 20:05:11 NDCG@5: 0.3255
2025-05-15 20:05:11 Recall@10: 0.4294
2025-05-15 20:05:11 NDCG@10: 0.3429
2025-05-15 20:05:11 Recall@20: 0.4384
2025-05-15 20:05:11 NDCG@20: 0.3452
2025-05-15 20:05:11 ==================================


2025-05-15 20:05:11 ================= Epoch 15/30 =================
2025-05-15 20:05:11 Train. Batch 0/5
2025-05-15 20:05:11 Train. loss_rec: 3.7025; loss_cl_pois: 2.4253; loss_cl_users: 0.6894; loss: 4.0140
2025-05-15 20:05:11 Train. Batch 1/5
2025-05-15 20:05:11 Train. loss_rec: 3.7039; loss_cl_pois: 2.4206; loss_cl_users: 0.6459; loss: 4.0106
2025-05-15 20:05:11 Train. Batch 2/5
2025-05-15 20:05:11 Train. loss_rec: 3.6581; loss_cl_pois: 2.4211; loss_cl_users: 0.5827; loss: 3.9585
2025-05-15 20:05:11 Train. Batch 3/5
2025-05-15 20:05:11 Train. loss_rec: 3.6647; loss_cl_pois: 2.4139; loss_cl_users: 0.6111; loss: 3.9672
2025-05-15 20:05:11 Train. Batch 4/5
2025-05-15 20:05:11 Train. loss_rec: 3.6124; loss_cl_pois: 2.4206; loss_cl_users: 0.1453; loss: 3.8690
2025-05-15 20:05:11 Training finishes at this epoch. It takes 0.005105062325795492 min
2025-05-15 20:05:11 Training loss: 3.9639
2025-05-15 20:05:11 Training Epoch 15/30 results:
2025-05-15 20:05:11 Recall@1: 1.0000
2025-05-15 20:05:11 NDCG@1: 1.0000
2025-05-15 20:05:11 Recall@5: 1.0000
2025-05-15 20:05:11 NDCG@5: 1.0000
2025-05-15 20:05:11 Recall@10: 1.0000
2025-05-15 20:05:11 NDCG@10: 1.0000
2025-05-15 20:05:11 Recall@20: 1.0000
2025-05-15 20:05:11 NDCG@20: 1.0000
2025-05-15 20:05:11 

2025-05-15 20:05:11 Testing
2025-05-15 20:05:11 Test. Batch 0/5
2025-05-15 20:05:11 Test. loss_rec: 7.0065; loss_cl_pois: 2.9328; loss_cl_users: 0.4528; loss: 7.3451
2025-05-15 20:05:11 Test. Batch 1/5
2025-05-15 20:05:11 Test. loss_rec: 6.6803; loss_cl_pois: 2.9311; loss_cl_users: 0.4516; loss: 7.0186
2025-05-15 20:05:11 Test. Batch 2/5
2025-05-15 20:05:11 Test. loss_rec: 6.5607; loss_cl_pois: 2.9301; loss_cl_users: 0.4409; loss: 6.8978
2025-05-15 20:05:11 Test. Batch 3/5
2025-05-15 20:05:11 Test. loss_rec: 6.7163; loss_cl_pois: 2.9354; loss_cl_users: 0.5124; loss: 7.0611
2025-05-15 20:05:11 Test. Batch 4/5
2025-05-15 20:05:11 Test. loss_rec: 6.2802; loss_cl_pois: 2.9277; loss_cl_users: 0.0807; loss: 6.5811
2025-05-15 20:05:11 Testing finishes
2025-05-15 20:05:11 Testing loss: 6.980725288391113
2025-05-15 20:05:11 Testing results:
2025-05-15 20:05:11 Recall@1: 0.2896
2025-05-15 20:05:11 NDCG@1: 0.2896
2025-05-15 20:05:11 Recall@5: 0.4090
2025-05-15 20:05:11 NDCG@5: 0.3538
2025-05-15 20:05:11 Recall@10: 0.4439
2025-05-15 20:05:11 NDCG@10: 0.3650
2025-05-15 20:05:11 Recall@20: 0.4559
2025-05-15 20:05:11 NDCG@20: 0.3682
2025-05-15 20:05:11 ==================================


2025-05-15 20:05:11 ================= Epoch 16/30 =================
2025-05-15 20:05:12 Train. Batch 0/5
2025-05-15 20:05:12 Train. loss_rec: 3.6212; loss_cl_pois: 2.4131; loss_cl_users: 0.7409; loss: 3.9366
2025-05-15 20:05:12 Train. Batch 1/5
2025-05-15 20:05:12 Train. loss_rec: 3.6124; loss_cl_pois: 2.4199; loss_cl_users: 0.5678; loss: 3.9112
2025-05-15 20:05:12 Train. Batch 2/5
2025-05-15 20:05:12 Train. loss_rec: 3.5998; loss_cl_pois: 2.4186; loss_cl_users: 0.6742; loss: 3.9091
2025-05-15 20:05:12 Train. Batch 3/5
2025-05-15 20:05:12 Train. loss_rec: 3.5787; loss_cl_pois: 2.4133; loss_cl_users: 0.6143; loss: 3.8815
2025-05-15 20:05:12 Train. Batch 4/5
2025-05-15 20:05:12 Train. loss_rec: 3.6175; loss_cl_pois: 2.4185; loss_cl_users: 0.1006; loss: 3.8694
2025-05-15 20:05:12 Training finishes at this epoch. It takes 0.005048187573750814 min
2025-05-15 20:05:12 Training loss: 3.9016
2025-05-15 20:05:12 Training Epoch 16/30 results:
2025-05-15 20:05:12 Recall@1: 1.0000
2025-05-15 20:05:12 NDCG@1: 1.0000
2025-05-15 20:05:12 Recall@5: 1.0000
2025-05-15 20:05:12 NDCG@5: 1.0000
2025-05-15 20:05:12 Recall@10: 1.0000
2025-05-15 20:05:12 NDCG@10: 1.0000
2025-05-15 20:05:12 Recall@20: 1.0000
2025-05-15 20:05:12 NDCG@20: 1.0000
2025-05-15 20:05:12 

2025-05-15 20:05:12 Testing
2025-05-15 20:05:12 Test. Batch 0/5
2025-05-15 20:05:12 Test. loss_rec: 6.7712; loss_cl_pois: 2.9272; loss_cl_users: 0.4445; loss: 7.1084
2025-05-15 20:05:12 Test. Batch 1/5
2025-05-15 20:05:12 Test. loss_rec: 6.7259; loss_cl_pois: 2.9296; loss_cl_users: 0.4761; loss: 7.0665
2025-05-15 20:05:12 Test. Batch 2/5
2025-05-15 20:05:12 Test. loss_rec: 6.7487; loss_cl_pois: 2.9159; loss_cl_users: 0.5260; loss: 7.0929
2025-05-15 20:05:12 Test. Batch 3/5
2025-05-15 20:05:12 Test. loss_rec: 6.6100; loss_cl_pois: 2.9277; loss_cl_users: 0.4857; loss: 6.9514
2025-05-15 20:05:12 Test. Batch 4/5
2025-05-15 20:05:12 Test. loss_rec: 6.3304; loss_cl_pois: 2.9319; loss_cl_users: 0.2147; loss: 6.6451
2025-05-15 20:05:12 Testing finishes
2025-05-15 20:05:12 Testing loss: 6.972849941253662
2025-05-15 20:05:12 Testing results:
2025-05-15 20:05:12 Recall@1: 0.2916
2025-05-15 20:05:12 NDCG@1: 0.2916
2025-05-15 20:05:12 Recall@5: 0.3944
2025-05-15 20:05:12 NDCG@5: 0.3457
2025-05-15 20:05:12 Recall@10: 0.4410
2025-05-15 20:05:12 NDCG@10: 0.3606
2025-05-15 20:05:12 Recall@20: 0.4500
2025-05-15 20:05:12 NDCG@20: 0.3630
2025-05-15 20:05:12 ==================================


2025-05-15 20:05:12 ================= Epoch 17/30 =================
2025-05-15 20:05:12 Train. Batch 0/5
2025-05-15 20:05:12 Train. loss_rec: 3.5551; loss_cl_pois: 2.4164; loss_cl_users: 0.5929; loss: 3.8560
2025-05-15 20:05:12 Train. Batch 1/5
2025-05-15 20:05:12 Train. loss_rec: 3.5295; loss_cl_pois: 2.4333; loss_cl_users: 0.8143; loss: 3.8542
2025-05-15 20:05:12 Train. Batch 2/5
2025-05-15 20:05:12 Train. loss_rec: 3.4992; loss_cl_pois: 2.4275; loss_cl_users: 0.7585; loss: 3.8178
2025-05-15 20:05:12 Train. Batch 3/5
2025-05-15 20:05:12 Train. loss_rec: 3.5209; loss_cl_pois: 2.4268; loss_cl_users: 0.7369; loss: 3.8372
2025-05-15 20:05:12 Train. Batch 4/5
2025-05-15 20:05:12 Train. loss_rec: 3.4581; loss_cl_pois: 2.4212; loss_cl_users: 0.0938; loss: 3.7096
2025-05-15 20:05:12 Training finishes at this epoch. It takes 0.005083727836608887 min
2025-05-15 20:05:12 Training loss: 3.8150
2025-05-15 20:05:12 Training Epoch 17/30 results:
2025-05-15 20:05:12 Recall@1: 1.0000
2025-05-15 20:05:12 NDCG@1: 1.0000
2025-05-15 20:05:12 Recall@5: 1.0000
2025-05-15 20:05:12 NDCG@5: 1.0000
2025-05-15 20:05:12 Recall@10: 1.0000
2025-05-15 20:05:12 NDCG@10: 1.0000
2025-05-15 20:05:12 Recall@20: 1.0000
2025-05-15 20:05:12 NDCG@20: 1.0000
2025-05-15 20:05:12 

2025-05-15 20:05:12 Testing
2025-05-15 20:05:12 Test. Batch 0/5
2025-05-15 20:05:12 Test. loss_rec: 6.6737; loss_cl_pois: 2.9260; loss_cl_users: 0.6185; loss: 7.0282
2025-05-15 20:05:12 Test. Batch 1/5
2025-05-15 20:05:12 Test. loss_rec: 6.7996; loss_cl_pois: 2.9241; loss_cl_users: 0.4548; loss: 7.1375
2025-05-15 20:05:12 Test. Batch 2/5
2025-05-15 20:05:12 Test. loss_rec: 6.7388; loss_cl_pois: 2.9350; loss_cl_users: 0.4764; loss: 7.0799
2025-05-15 20:05:13 Test. Batch 3/5
2025-05-15 20:05:13 Test. loss_rec: 6.5544; loss_cl_pois: 2.9340; loss_cl_users: 0.4748; loss: 6.8953
2025-05-15 20:05:13 Test. Batch 4/5
2025-05-15 20:05:13 Test. loss_rec: 6.4850; loss_cl_pois: 2.9328; loss_cl_users: 0.1107; loss: 6.7893
2025-05-15 20:05:13 Testing finishes
2025-05-15 20:05:13 Testing loss: 6.986046981811524
2025-05-15 20:05:13 Testing results:
2025-05-15 20:05:13 Recall@1: 0.2729
2025-05-15 20:05:13 NDCG@1: 0.2729
2025-05-15 20:05:13 Recall@5: 0.3884
2025-05-15 20:05:13 NDCG@5: 0.3366
2025-05-15 20:05:13 Recall@10: 0.4341
2025-05-15 20:05:13 NDCG@10: 0.3516
2025-05-15 20:05:13 Recall@20: 0.4510
2025-05-15 20:05:13 NDCG@20: 0.3561
2025-05-15 20:05:13 ==================================


2025-05-15 20:05:13 ================= Epoch 18/30 =================
2025-05-15 20:05:13 Train. Batch 0/5
2025-05-15 20:05:13 Train. loss_rec: 3.4641; loss_cl_pois: 2.4239; loss_cl_users: 0.5991; loss: 3.7665
2025-05-15 20:05:13 Train. Batch 1/5
2025-05-15 20:05:13 Train. loss_rec: 3.4735; loss_cl_pois: 2.4130; loss_cl_users: 0.7186; loss: 3.7867
2025-05-15 20:05:13 Train. Batch 2/5
2025-05-15 20:05:13 Train. loss_rec: 3.4443; loss_cl_pois: 2.4177; loss_cl_users: 0.7900; loss: 3.7650
2025-05-15 20:05:13 Train. Batch 3/5
2025-05-15 20:05:13 Train. loss_rec: 3.4428; loss_cl_pois: 2.4181; loss_cl_users: 0.8547; loss: 3.7701
2025-05-15 20:05:13 Train. Batch 4/5
2025-05-15 20:05:13 Train. loss_rec: 3.3803; loss_cl_pois: 2.4298; loss_cl_users: 0.0960; loss: 3.6329
2025-05-15 20:05:13 Training finishes at this epoch. It takes 0.005058944225311279 min
2025-05-15 20:05:13 Training loss: 3.7442
2025-05-15 20:05:13 Training Epoch 18/30 results:
2025-05-15 20:05:13 Recall@1: 1.0000
2025-05-15 20:05:13 NDCG@1: 1.0000
2025-05-15 20:05:13 Recall@5: 1.0000
2025-05-15 20:05:13 NDCG@5: 1.0000
2025-05-15 20:05:13 Recall@10: 1.0000
2025-05-15 20:05:13 NDCG@10: 1.0000
2025-05-15 20:05:13 Recall@20: 1.0000
2025-05-15 20:05:13 NDCG@20: 1.0000
2025-05-15 20:05:13 

2025-05-15 20:05:13 Testing
2025-05-15 20:05:13 Test. Batch 0/5
2025-05-15 20:05:13 Test. loss_rec: 6.5954; loss_cl_pois: 2.9396; loss_cl_users: 0.4464; loss: 6.9340
2025-05-15 20:05:13 Test. Batch 1/5
2025-05-15 20:05:13 Test. loss_rec: 6.7704; loss_cl_pois: 2.9385; loss_cl_users: 0.5386; loss: 7.1181
2025-05-15 20:05:13 Test. Batch 2/5
2025-05-15 20:05:13 Test. loss_rec: 6.6270; loss_cl_pois: 2.9428; loss_cl_users: 0.4987; loss: 6.9712
2025-05-15 20:05:13 Test. Batch 3/5
2025-05-15 20:05:13 Test. loss_rec: 6.6409; loss_cl_pois: 2.9362; loss_cl_users: 0.5121; loss: 6.9857
2025-05-15 20:05:13 Test. Batch 4/5
2025-05-15 20:05:13 Test. loss_rec: 6.6920; loss_cl_pois: 2.9410; loss_cl_users: 0.1122; loss: 6.9973
2025-05-15 20:05:13 Testing finishes
2025-05-15 20:05:13 Testing loss: 7.001251983642578
2025-05-15 20:05:13 Testing results:
2025-05-15 20:05:13 Recall@1: 0.2818
2025-05-15 20:05:13 NDCG@1: 0.2818
2025-05-15 20:05:13 Recall@5: 0.3915
2025-05-15 20:05:13 NDCG@5: 0.3377
2025-05-15 20:05:13 Recall@10: 0.4195
2025-05-15 20:05:13 NDCG@10: 0.3470
2025-05-15 20:05:13 Recall@20: 0.4355
2025-05-15 20:05:13 NDCG@20: 0.3511
2025-05-15 20:05:13 ==================================


2025-05-15 20:05:13 ================= Epoch 19/30 =================
2025-05-15 20:05:13 Train. Batch 0/5
2025-05-15 20:05:13 Train. loss_rec: 3.4192; loss_cl_pois: 2.4252; loss_cl_users: 0.8351; loss: 3.7453
2025-05-15 20:05:13 Train. Batch 1/5
2025-05-15 20:05:13 Train. loss_rec: 3.3902; loss_cl_pois: 2.4203; loss_cl_users: 0.7411; loss: 3.7064
2025-05-15 20:05:13 Train. Batch 2/5
2025-05-15 20:05:13 Train. loss_rec: 3.3808; loss_cl_pois: 2.4361; loss_cl_users: 0.7636; loss: 3.7008
2025-05-15 20:05:13 Train. Batch 3/5
2025-05-15 20:05:13 Train. loss_rec: 3.3704; loss_cl_pois: 2.4167; loss_cl_users: 0.8246; loss: 3.6945
2025-05-15 20:05:13 Train. Batch 4/5
2025-05-15 20:05:13 Train. loss_rec: 3.3676; loss_cl_pois: 2.4187; loss_cl_users: 0.0880; loss: 3.6183
2025-05-15 20:05:13 Training finishes at this epoch. It takes 0.00511785348256429 min
2025-05-15 20:05:13 Training loss: 3.6930
2025-05-15 20:05:13 Training Epoch 19/30 results:
2025-05-15 20:05:13 Recall@1: 1.0000
2025-05-15 20:05:13 NDCG@1: 1.0000
2025-05-15 20:05:13 Recall@5: 1.0000
2025-05-15 20:05:13 NDCG@5: 1.0000
2025-05-15 20:05:13 Recall@10: 1.0000
2025-05-15 20:05:13 NDCG@10: 1.0000
2025-05-15 20:05:13 Recall@20: 1.0000
2025-05-15 20:05:13 NDCG@20: 1.0000
2025-05-15 20:05:13 

2025-05-15 20:05:13 Testing
2025-05-15 20:05:13 Test. Batch 0/5
2025-05-15 20:05:13 Test. loss_rec: 6.7849; loss_cl_pois: 2.9411; loss_cl_users: 0.4792; loss: 7.1269
2025-05-15 20:05:14 Test. Batch 1/5
2025-05-15 20:05:14 Test. loss_rec: 6.6739; loss_cl_pois: 2.9376; loss_cl_users: 0.5321; loss: 7.0209
2025-05-15 20:05:14 Test. Batch 2/5
2025-05-15 20:05:14 Test. loss_rec: 6.4278; loss_cl_pois: 2.9379; loss_cl_users: 0.5304; loss: 6.7746
2025-05-15 20:05:14 Test. Batch 3/5
2025-05-15 20:05:14 Test. loss_rec: 6.7692; loss_cl_pois: 2.9390; loss_cl_users: 0.4950; loss: 7.1126
2025-05-15 20:05:14 Test. Batch 4/5
2025-05-15 20:05:14 Test. loss_rec: 6.1275; loss_cl_pois: 2.9393; loss_cl_users: 0.0978; loss: 6.4312
2025-05-15 20:05:14 Testing finishes
2025-05-15 20:05:14 Testing loss: 6.893239879608155
2025-05-15 20:05:14 Testing results:
2025-05-15 20:05:14 Recall@1: 0.2867
2025-05-15 20:05:14 NDCG@1: 0.2867
2025-05-15 20:05:14 Recall@5: 0.4099
2025-05-15 20:05:14 NDCG@5: 0.3543
2025-05-15 20:05:14 Recall@10: 0.4429
2025-05-15 20:05:14 NDCG@10: 0.3651
2025-05-15 20:05:14 Recall@20: 0.4646
2025-05-15 20:05:14 NDCG@20: 0.3705
2025-05-15 20:05:14 ==================================


2025-05-15 20:05:14 ================= Epoch 20/30 =================
2025-05-15 20:05:14 Train. Batch 0/5
2025-05-15 20:05:14 Train. loss_rec: 3.3459; loss_cl_pois: 2.4235; loss_cl_users: 0.6863; loss: 3.6569
2025-05-15 20:05:14 Train. Batch 1/5
2025-05-15 20:05:14 Train. loss_rec: 3.3382; loss_cl_pois: 2.4317; loss_cl_users: 0.8054; loss: 3.6619
2025-05-15 20:05:14 Train. Batch 2/5
2025-05-15 20:05:14 Train. loss_rec: 3.3198; loss_cl_pois: 2.4244; loss_cl_users: 0.7578; loss: 3.6380
2025-05-15 20:05:14 Train. Batch 3/5
2025-05-15 20:05:14 Train. loss_rec: 3.3186; loss_cl_pois: 2.4217; loss_cl_users: 0.8049; loss: 3.6412
2025-05-15 20:05:14 Train. Batch 4/5
2025-05-15 20:05:14 Train. loss_rec: 3.3293; loss_cl_pois: 2.4199; loss_cl_users: 0.0983; loss: 3.5811
2025-05-15 20:05:14 Training finishes at this epoch. It takes 0.005095752080281576 min
2025-05-15 20:05:14 Training loss: 3.6358
2025-05-15 20:05:14 Training Epoch 20/30 results:
2025-05-15 20:05:14 Recall@1: 1.0000
2025-05-15 20:05:14 NDCG@1: 1.0000
2025-05-15 20:05:14 Recall@5: 1.0000
2025-05-15 20:05:14 NDCG@5: 1.0000
2025-05-15 20:05:14 Recall@10: 1.0000
2025-05-15 20:05:14 NDCG@10: 1.0000
2025-05-15 20:05:14 Recall@20: 1.0000
2025-05-15 20:05:14 NDCG@20: 1.0000
2025-05-15 20:05:14 

2025-05-15 20:05:14 Testing
2025-05-15 20:05:14 Test. Batch 0/5
2025-05-15 20:05:14 Test. loss_rec: 6.5926; loss_cl_pois: 2.9477; loss_cl_users: 0.5882; loss: 6.9462
2025-05-15 20:05:14 Test. Batch 1/5
2025-05-15 20:05:14 Test. loss_rec: 6.4478; loss_cl_pois: 2.9465; loss_cl_users: 0.5259; loss: 6.7950
2025-05-15 20:05:14 Test. Batch 2/5
2025-05-15 20:05:14 Test. loss_rec: 6.8657; loss_cl_pois: 2.9472; loss_cl_users: 0.5495; loss: 7.2154
2025-05-15 20:05:14 Test. Batch 3/5
2025-05-15 20:05:14 Test. loss_rec: 6.6290; loss_cl_pois: 2.9458; loss_cl_users: 0.5121; loss: 6.9748
2025-05-15 20:05:14 Test. Batch 4/5
2025-05-15 20:05:14 Test. loss_rec: 6.5955; loss_cl_pois: 2.9421; loss_cl_users: 0.0724; loss: 6.8969
2025-05-15 20:05:14 Testing finishes
2025-05-15 20:05:14 Testing loss: 6.965654277801514
2025-05-15 20:05:14 Testing results:
2025-05-15 20:05:14 Recall@1: 0.2808
2025-05-15 20:05:14 NDCG@1: 0.2808
2025-05-15 20:05:14 Recall@5: 0.3904
2025-05-15 20:05:14 NDCG@5: 0.3389
2025-05-15 20:05:14 Recall@10: 0.4234
2025-05-15 20:05:14 NDCG@10: 0.3500
2025-05-15 20:05:14 Recall@20: 0.4374
2025-05-15 20:05:14 NDCG@20: 0.3536
2025-05-15 20:05:14 ==================================


2025-05-15 20:05:14 ================= Epoch 21/30 =================
2025-05-15 20:05:14 Train. Batch 0/5
2025-05-15 20:05:14 Train. loss_rec: 3.2789; loss_cl_pois: 2.4164; loss_cl_users: 0.8090; loss: 3.6014
2025-05-15 20:05:14 Train. Batch 1/5
2025-05-15 20:05:14 Train. loss_rec: 3.2762; loss_cl_pois: 2.4309; loss_cl_users: 0.8051; loss: 3.5998
2025-05-15 20:05:14 Train. Batch 2/5
2025-05-15 20:05:14 Train. loss_rec: 3.2518; loss_cl_pois: 2.4172; loss_cl_users: 0.8379; loss: 3.5773
2025-05-15 20:05:14 Train. Batch 3/5
2025-05-15 20:05:14 Train. loss_rec: 3.2534; loss_cl_pois: 2.4236; loss_cl_users: 0.7435; loss: 3.5701
2025-05-15 20:05:14 Train. Batch 4/5
2025-05-15 20:05:14 Train. loss_rec: 3.3013; loss_cl_pois: 2.4162; loss_cl_users: 0.1062; loss: 3.5535
2025-05-15 20:05:15 Training finishes at this epoch. It takes 0.005114122231801351 min
2025-05-15 20:05:15 Training loss: 3.5804
2025-05-15 20:05:15 Training Epoch 21/30 results:
2025-05-15 20:05:15 Recall@1: 1.0000
2025-05-15 20:05:15 NDCG@1: 1.0000
2025-05-15 20:05:15 Recall@5: 1.0000
2025-05-15 20:05:15 NDCG@5: 1.0000
2025-05-15 20:05:15 Recall@10: 1.0000
2025-05-15 20:05:15 NDCG@10: 1.0000
2025-05-15 20:05:15 Recall@20: 1.0000
2025-05-15 20:05:15 NDCG@20: 1.0000
2025-05-15 20:05:15 

2025-05-15 20:05:15 Testing
2025-05-15 20:05:15 Test. Batch 0/5
2025-05-15 20:05:15 Test. loss_rec: 6.7616; loss_cl_pois: 2.9466; loss_cl_users: 0.4957; loss: 7.1058
2025-05-15 20:05:15 Test. Batch 1/5
2025-05-15 20:05:15 Test. loss_rec: 6.4406; loss_cl_pois: 2.9401; loss_cl_users: 0.5559; loss: 6.7902
2025-05-15 20:05:15 Test. Batch 2/5
2025-05-15 20:05:15 Test. loss_rec: 6.8277; loss_cl_pois: 2.9361; loss_cl_users: 0.5737; loss: 7.1787
2025-05-15 20:05:15 Test. Batch 3/5
2025-05-15 20:05:15 Test. loss_rec: 6.4260; loss_cl_pois: 2.9504; loss_cl_users: 0.5010; loss: 6.7711
2025-05-15 20:05:15 Test. Batch 4/5
2025-05-15 20:05:15 Test. loss_rec: 6.4885; loss_cl_pois: 2.9456; loss_cl_users: 0.0763; loss: 6.7907
2025-05-15 20:05:15 Testing finishes
2025-05-15 20:05:15 Testing loss: 6.9272950172424315
2025-05-15 20:05:15 Testing results:
2025-05-15 20:05:15 Recall@1: 0.2788
2025-05-15 20:05:15 NDCG@1: 0.2788
2025-05-15 20:05:15 Recall@5: 0.4052
2025-05-15 20:05:15 NDCG@5: 0.3475
2025-05-15 20:05:15 Recall@10: 0.4312
2025-05-15 20:05:15 NDCG@10: 0.3560
2025-05-15 20:05:15 Recall@20: 0.4422
2025-05-15 20:05:15 NDCG@20: 0.3587
2025-05-15 20:05:15 ==================================


2025-05-15 20:05:15 ================= Epoch 22/30 =================
2025-05-15 20:05:15 Train. Batch 0/5
2025-05-15 20:05:15 Train. loss_rec: 3.2209; loss_cl_pois: 2.4250; loss_cl_users: 0.8381; loss: 3.5472
2025-05-15 20:05:15 Train. Batch 1/5
2025-05-15 20:05:15 Train. loss_rec: 3.2073; loss_cl_pois: 2.4176; loss_cl_users: 0.8905; loss: 3.5382
2025-05-15 20:05:15 Train. Batch 2/5
2025-05-15 20:05:15 Train. loss_rec: 3.2055; loss_cl_pois: 2.4224; loss_cl_users: 0.8697; loss: 3.5347
2025-05-15 20:05:15 Train. Batch 3/5
2025-05-15 20:05:15 Train. loss_rec: 3.1891; loss_cl_pois: 2.4255; loss_cl_users: 0.7864; loss: 3.5103
2025-05-15 20:05:15 Train. Batch 4/5
2025-05-15 20:05:15 Train. loss_rec: 3.2054; loss_cl_pois: 2.4203; loss_cl_users: 0.1005; loss: 3.4575
2025-05-15 20:05:15 Training finishes at this epoch. It takes 0.005166180928548177 min
2025-05-15 20:05:15 Training loss: 3.5176
2025-05-15 20:05:15 Training Epoch 22/30 results:
2025-05-15 20:05:15 Recall@1: 0.9990
2025-05-15 20:05:15 NDCG@1: 0.9990
2025-05-15 20:05:15 Recall@5: 1.0000
2025-05-15 20:05:15 NDCG@5: 0.9996
2025-05-15 20:05:15 Recall@10: 1.0000
2025-05-15 20:05:15 NDCG@10: 0.9996
2025-05-15 20:05:15 Recall@20: 1.0000
2025-05-15 20:05:15 NDCG@20: 0.9996
2025-05-15 20:05:15 

2025-05-15 20:05:15 Testing
2025-05-15 20:05:15 Test. Batch 0/5
2025-05-15 20:05:15 Test. loss_rec: 6.5782; loss_cl_pois: 2.9612; loss_cl_users: 0.5239; loss: 6.9267
2025-05-15 20:05:15 Test. Batch 1/5
2025-05-15 20:05:15 Test. loss_rec: 6.5707; loss_cl_pois: 2.9604; loss_cl_users: 0.5094; loss: 6.9177
2025-05-15 20:05:15 Test. Batch 2/5
2025-05-15 20:05:15 Test. loss_rec: 6.4946; loss_cl_pois: 2.9418; loss_cl_users: 0.6272; loss: 6.8515
2025-05-15 20:05:15 Test. Batch 3/5
2025-05-15 20:05:15 Test. loss_rec: 6.6750; loss_cl_pois: 2.9542; loss_cl_users: 0.5225; loss: 7.0226
2025-05-15 20:05:15 Test. Batch 4/5
2025-05-15 20:05:15 Test. loss_rec: 6.6483; loss_cl_pois: 2.9527; loss_cl_users: 0.1300; loss: 6.9565
2025-05-15 20:05:15 Testing finishes
2025-05-15 20:05:15 Testing loss: 6.9350152015686035
2025-05-15 20:05:15 Testing results:
2025-05-15 20:05:15 Recall@1: 0.2788
2025-05-15 20:05:15 NDCG@1: 0.2788
2025-05-15 20:05:15 Recall@5: 0.3895
2025-05-15 20:05:15 NDCG@5: 0.3363
2025-05-15 20:05:15 Recall@10: 0.4254
2025-05-15 20:05:15 NDCG@10: 0.3483
2025-05-15 20:05:15 Recall@20: 0.4442
2025-05-15 20:05:15 NDCG@20: 0.3529
2025-05-15 20:05:15 ==================================


2025-05-15 20:05:15 ================= Epoch 23/30 =================
2025-05-15 20:05:15 Train. Batch 0/5
2025-05-15 20:05:15 Train. loss_rec: 3.1670; loss_cl_pois: 2.4191; loss_cl_users: 0.7867; loss: 3.4876
2025-05-15 20:05:15 Train. Batch 1/5
2025-05-15 20:05:15 Train. loss_rec: 3.1538; loss_cl_pois: 2.4259; loss_cl_users: 0.8640; loss: 3.4828
2025-05-15 20:05:15 Train. Batch 2/5
2025-05-15 20:05:15 Train. loss_rec: 3.1543; loss_cl_pois: 2.4298; loss_cl_users: 0.7891; loss: 3.4762
2025-05-15 20:05:16 Train. Batch 3/5
2025-05-15 20:05:16 Train. loss_rec: 3.1316; loss_cl_pois: 2.4211; loss_cl_users: 0.9258; loss: 3.4663
2025-05-15 20:05:16 Train. Batch 4/5
2025-05-15 20:05:16 Train. loss_rec: 3.1491; loss_cl_pois: 2.4216; loss_cl_users: 0.1188; loss: 3.4032
2025-05-15 20:05:16 Training finishes at this epoch. It takes 0.005147965749104818 min
2025-05-15 20:05:16 Training loss: 3.4632
2025-05-15 20:05:16 Training Epoch 23/30 results:
2025-05-15 20:05:16 Recall@1: 0.9990
2025-05-15 20:05:16 NDCG@1: 0.9990
2025-05-15 20:05:16 Recall@5: 1.0000
2025-05-15 20:05:16 NDCG@5: 0.9996
2025-05-15 20:05:16 Recall@10: 1.0000
2025-05-15 20:05:16 NDCG@10: 0.9996
2025-05-15 20:05:16 Recall@20: 1.0000
2025-05-15 20:05:16 NDCG@20: 0.9996
2025-05-15 20:05:16 

2025-05-15 20:05:16 Testing
2025-05-15 20:05:16 Test. Batch 0/5
2025-05-15 20:05:16 Test. loss_rec: 6.6607; loss_cl_pois: 2.9573; loss_cl_users: 0.5464; loss: 7.0110
2025-05-15 20:05:16 Test. Batch 1/5
2025-05-15 20:05:16 Test. loss_rec: 6.5267; loss_cl_pois: 2.9590; loss_cl_users: 0.5752; loss: 6.8802
2025-05-15 20:05:16 Test. Batch 2/5
2025-05-15 20:05:16 Test. loss_rec: 6.5416; loss_cl_pois: 2.9519; loss_cl_users: 0.6633; loss: 6.9032
2025-05-15 20:05:16 Test. Batch 3/5
2025-05-15 20:05:16 Test. loss_rec: 6.6422; loss_cl_pois: 2.9626; loss_cl_users: 0.4980; loss: 6.9882
2025-05-15 20:05:16 Test. Batch 4/5
2025-05-15 20:05:16 Test. loss_rec: 6.0125; loss_cl_pois: 2.9688; loss_cl_users: 0.1323; loss: 6.3226
2025-05-15 20:05:16 Testing finishes
2025-05-15 20:05:16 Testing loss: 6.82103967666626
2025-05-15 20:05:16 Testing results:
2025-05-15 20:05:16 Recall@1: 0.2798
2025-05-15 20:05:16 NDCG@1: 0.2798
2025-05-15 20:05:16 Recall@5: 0.4090
2025-05-15 20:05:16 NDCG@5: 0.3477
2025-05-15 20:05:16 Recall@10: 0.4468
2025-05-15 20:05:16 NDCG@10: 0.3603
2025-05-15 20:05:16 Recall@20: 0.4675
2025-05-15 20:05:16 NDCG@20: 0.3657
2025-05-15 20:05:16 ==================================


2025-05-15 20:05:16 ================= Epoch 24/30 =================
2025-05-15 20:05:16 Train. Batch 0/5
2025-05-15 20:05:16 Train. loss_rec: 3.1145; loss_cl_pois: 2.4256; loss_cl_users: 0.7893; loss: 3.4360
2025-05-15 20:05:16 Train. Batch 1/5
2025-05-15 20:05:16 Train. loss_rec: 3.0842; loss_cl_pois: 2.4241; loss_cl_users: 0.9054; loss: 3.4171
2025-05-15 20:05:16 Train. Batch 2/5
2025-05-15 20:05:16 Train. loss_rec: 3.1193; loss_cl_pois: 2.4254; loss_cl_users: 0.7550; loss: 3.4373
2025-05-15 20:05:16 Train. Batch 3/5
2025-05-15 20:05:16 Train. loss_rec: 3.0946; loss_cl_pois: 2.4185; loss_cl_users: 0.9464; loss: 3.4311
2025-05-15 20:05:16 Train. Batch 4/5
2025-05-15 20:05:16 Train. loss_rec: 3.1169; loss_cl_pois: 2.4134; loss_cl_users: 0.0899; loss: 3.3672
2025-05-15 20:05:16 Training finishes at this epoch. It takes 0.005191544691721599 min
2025-05-15 20:05:16 Training loss: 3.4178
2025-05-15 20:05:16 Training Epoch 24/30 results:
2025-05-15 20:05:16 Recall@1: 1.0000
2025-05-15 20:05:16 NDCG@1: 1.0000
2025-05-15 20:05:16 Recall@5: 1.0000
2025-05-15 20:05:16 NDCG@5: 1.0000
2025-05-15 20:05:16 Recall@10: 1.0000
2025-05-15 20:05:16 NDCG@10: 1.0000
2025-05-15 20:05:16 Recall@20: 1.0000
2025-05-15 20:05:16 NDCG@20: 1.0000
2025-05-15 20:05:16 

2025-05-15 20:05:16 Testing
2025-05-15 20:05:16 Test. Batch 0/5
2025-05-15 20:05:16 Test. loss_rec: 6.6645; loss_cl_pois: 2.9676; loss_cl_users: 0.5732; loss: 7.0186
2025-05-15 20:05:16 Test. Batch 1/5
2025-05-15 20:05:16 Test. loss_rec: 6.5591; loss_cl_pois: 2.9553; loss_cl_users: 0.5953; loss: 6.9141
2025-05-15 20:05:16 Test. Batch 2/5
2025-05-15 20:05:16 Test. loss_rec: 6.2882; loss_cl_pois: 2.9649; loss_cl_users: 0.5642; loss: 6.6411
2025-05-15 20:05:16 Test. Batch 3/5
2025-05-15 20:05:16 Test. loss_rec: 6.6415; loss_cl_pois: 2.9636; loss_cl_users: 0.5035; loss: 6.9882
2025-05-15 20:05:16 Test. Batch 4/5
2025-05-15 20:05:16 Test. loss_rec: 7.1203; loss_cl_pois: 2.9479; loss_cl_users: 0.0822; loss: 7.4233
2025-05-15 20:05:16 Testing finishes
2025-05-15 20:05:16 Testing loss: 6.997058391571045
2025-05-15 20:05:16 Testing results:
2025-05-15 20:05:16 Recall@1: 0.2554
2025-05-15 20:05:16 NDCG@1: 0.2554
2025-05-15 20:05:16 Recall@5: 0.3669
2025-05-15 20:05:16 NDCG@5: 0.3159
2025-05-15 20:05:16 Recall@10: 0.4107
2025-05-15 20:05:16 NDCG@10: 0.3305
2025-05-15 20:05:16 Recall@20: 0.4256
2025-05-15 20:05:16 NDCG@20: 0.3343
2025-05-15 20:05:16 ==================================


2025-05-15 20:05:16 ================= Epoch 25/30 =================
2025-05-15 20:05:16 Train. Batch 0/5
2025-05-15 20:05:16 Train. loss_rec: 3.0687; loss_cl_pois: 2.4201; loss_cl_users: 0.7493; loss: 3.3856
2025-05-15 20:05:16 Train. Batch 1/5
2025-05-15 20:05:17 Train. loss_rec: 3.0638; loss_cl_pois: 2.4264; loss_cl_users: 0.9151; loss: 3.3979
2025-05-15 20:05:17 Train. Batch 2/5
2025-05-15 20:05:17 Train. loss_rec: 3.0382; loss_cl_pois: 2.4205; loss_cl_users: 0.9678; loss: 3.3770
2025-05-15 20:05:17 Train. Batch 3/5
2025-05-15 20:05:17 Train. loss_rec: 3.0279; loss_cl_pois: 2.4130; loss_cl_users: 0.8053; loss: 3.3497
2025-05-15 20:05:17 Train. Batch 4/5
2025-05-15 20:05:17 Train. loss_rec: 3.0494; loss_cl_pois: 2.4137; loss_cl_users: 0.2245; loss: 3.3133
2025-05-15 20:05:17 Training finishes at this epoch. It takes 0.005068198839823405 min
2025-05-15 20:05:17 Training loss: 3.3647
2025-05-15 20:05:17 Training Epoch 25/30 results:
2025-05-15 20:05:17 Recall@1: 1.0000
2025-05-15 20:05:17 NDCG@1: 1.0000
2025-05-15 20:05:17 Recall@5: 1.0000
2025-05-15 20:05:17 NDCG@5: 1.0000
2025-05-15 20:05:17 Recall@10: 1.0000
2025-05-15 20:05:17 NDCG@10: 1.0000
2025-05-15 20:05:17 Recall@20: 1.0000
2025-05-15 20:05:17 NDCG@20: 1.0000
2025-05-15 20:05:17 

2025-05-15 20:05:17 Testing
2025-05-15 20:05:17 Test. Batch 0/5
2025-05-15 20:05:17 Test. loss_rec: 6.5610; loss_cl_pois: 2.9629; loss_cl_users: 0.5971; loss: 6.9170
2025-05-15 20:05:17 Test. Batch 1/5
2025-05-15 20:05:17 Test. loss_rec: 6.6795; loss_cl_pois: 2.9566; loss_cl_users: 0.5588; loss: 7.0311
2025-05-15 20:05:17 Test. Batch 2/5
2025-05-15 20:05:17 Test. loss_rec: 6.4442; loss_cl_pois: 2.9507; loss_cl_users: 0.5365; loss: 6.7929
2025-05-15 20:05:17 Test. Batch 3/5
2025-05-15 20:05:17 Test. loss_rec: 6.6157; loss_cl_pois: 2.9596; loss_cl_users: 0.5696; loss: 6.9686
2025-05-15 20:05:17 Test. Batch 4/5
2025-05-15 20:05:17 Test. loss_rec: 5.8544; loss_cl_pois: 2.9524; loss_cl_users: 0.0865; loss: 6.1583
2025-05-15 20:05:17 Testing finishes
2025-05-15 20:05:17 Testing loss: 6.773582172393799
2025-05-15 20:05:17 Testing results:
2025-05-15 20:05:17 Recall@1: 0.2945
2025-05-15 20:05:17 NDCG@1: 0.2945
2025-05-15 20:05:17 Recall@5: 0.4129
2025-05-15 20:05:17 NDCG@5: 0.3575
2025-05-15 20:05:17 Recall@10: 0.4389
2025-05-15 20:05:17 NDCG@10: 0.3662
2025-05-15 20:05:17 Recall@20: 0.4529
2025-05-15 20:05:17 NDCG@20: 0.3699
2025-05-15 20:05:17 ==================================


2025-05-15 20:05:17 ================= Epoch 26/30 =================
2025-05-15 20:05:17 Train. Batch 0/5
2025-05-15 20:05:17 Train. loss_rec: 3.0257; loss_cl_pois: 2.4199; loss_cl_users: 0.8871; loss: 3.3564
2025-05-15 20:05:17 Train. Batch 1/5
2025-05-15 20:05:17 Train. loss_rec: 3.0142; loss_cl_pois: 2.4147; loss_cl_users: 0.8007; loss: 3.3357
2025-05-15 20:05:17 Train. Batch 2/5
2025-05-15 20:05:17 Train. loss_rec: 2.9997; loss_cl_pois: 2.4138; loss_cl_users: 1.0330; loss: 3.3444
2025-05-15 20:05:17 Train. Batch 3/5
2025-05-15 20:05:17 Train. loss_rec: 3.0011; loss_cl_pois: 2.4074; loss_cl_users: 0.7464; loss: 3.3165
2025-05-15 20:05:17 Train. Batch 4/5
2025-05-15 20:05:17 Train. loss_rec: 2.9655; loss_cl_pois: 2.3993; loss_cl_users: 0.1235; loss: 3.2178
2025-05-15 20:05:17 Training finishes at this epoch. It takes 0.00513302485148112 min
2025-05-15 20:05:17 Training loss: 3.3142
2025-05-15 20:05:17 Training Epoch 26/30 results:
2025-05-15 20:05:17 Recall@1: 1.0000
2025-05-15 20:05:17 NDCG@1: 1.0000
2025-05-15 20:05:17 Recall@5: 1.0000
2025-05-15 20:05:17 NDCG@5: 1.0000
2025-05-15 20:05:17 Recall@10: 1.0000
2025-05-15 20:05:17 NDCG@10: 1.0000
2025-05-15 20:05:17 Recall@20: 1.0000
2025-05-15 20:05:17 NDCG@20: 1.0000
2025-05-15 20:05:17 

2025-05-15 20:05:17 Testing
2025-05-15 20:05:17 Test. Batch 0/5
2025-05-15 20:05:17 Test. loss_rec: 6.6389; loss_cl_pois: 2.9578; loss_cl_users: 0.4773; loss: 6.9824
2025-05-15 20:05:17 Test. Batch 1/5
2025-05-15 20:05:17 Test. loss_rec: 6.5149; loss_cl_pois: 2.9730; loss_cl_users: 0.6172; loss: 6.8739
2025-05-15 20:05:17 Test. Batch 2/5
2025-05-15 20:05:17 Test. loss_rec: 6.6045; loss_cl_pois: 2.9559; loss_cl_users: 0.5709; loss: 6.9572
2025-05-15 20:05:17 Test. Batch 3/5
2025-05-15 20:05:17 Test. loss_rec: 6.4428; loss_cl_pois: 2.9547; loss_cl_users: 0.5427; loss: 6.7926
2025-05-15 20:05:17 Test. Batch 4/5
2025-05-15 20:05:17 Test. loss_rec: 6.1463; loss_cl_pois: 2.9535; loss_cl_users: 0.1216; loss: 6.4539
2025-05-15 20:05:18 Testing finishes
2025-05-15 20:05:18 Testing loss: 6.8119837760925295
2025-05-15 20:05:18 Testing results:
2025-05-15 20:05:18 Recall@1: 0.2926
2025-05-15 20:05:18 NDCG@1: 0.2926
2025-05-15 20:05:18 Recall@5: 0.4090
2025-05-15 20:05:18 NDCG@5: 0.3549
2025-05-15 20:05:18 Recall@10: 0.4458
2025-05-15 20:05:18 NDCG@10: 0.3669
2025-05-15 20:05:18 Recall@20: 0.4558
2025-05-15 20:05:18 NDCG@20: 0.3695
2025-05-15 20:05:18 ==================================


2025-05-15 20:05:18 ================= Epoch 27/30 =================
2025-05-15 20:05:18 Train. Batch 0/5
2025-05-15 20:05:18 Train. loss_rec: 2.9702; loss_cl_pois: 2.4079; loss_cl_users: 0.8610; loss: 3.2971
2025-05-15 20:05:18 Train. Batch 1/5
2025-05-15 20:05:18 Train. loss_rec: 2.9587; loss_cl_pois: 2.4111; loss_cl_users: 0.8869; loss: 3.2885
2025-05-15 20:05:18 Train. Batch 2/5
2025-05-15 20:05:18 Train. loss_rec: 2.9633; loss_cl_pois: 2.4115; loss_cl_users: 0.8657; loss: 3.2910
2025-05-15 20:05:18 Train. Batch 3/5
2025-05-15 20:05:18 Train. loss_rec: 2.9303; loss_cl_pois: 2.4171; loss_cl_users: 0.9671; loss: 3.2687
2025-05-15 20:05:18 Train. Batch 4/5
2025-05-15 20:05:18 Train. loss_rec: 2.9520; loss_cl_pois: 2.4208; loss_cl_users: 0.1393; loss: 3.2080
2025-05-15 20:05:18 Training finishes at this epoch. It takes 0.005304443836212158 min
2025-05-15 20:05:18 Training loss: 3.2707
2025-05-15 20:05:18 Training Epoch 27/30 results:
2025-05-15 20:05:18 Recall@1: 0.9990
2025-05-15 20:05:18 NDCG@1: 0.9990
2025-05-15 20:05:18 Recall@5: 1.0000
2025-05-15 20:05:18 NDCG@5: 0.9996
2025-05-15 20:05:18 Recall@10: 1.0000
2025-05-15 20:05:18 NDCG@10: 0.9996
2025-05-15 20:05:18 Recall@20: 1.0000
2025-05-15 20:05:18 NDCG@20: 0.9996
2025-05-15 20:05:18 

2025-05-15 20:05:18 Testing
2025-05-15 20:05:18 Test. Batch 0/5
2025-05-15 20:05:18 Test. loss_rec: 6.4192; loss_cl_pois: 2.9784; loss_cl_users: 0.6465; loss: 6.7817
2025-05-15 20:05:18 Test. Batch 1/5
2025-05-15 20:05:18 Test. loss_rec: 6.6335; loss_cl_pois: 2.9820; loss_cl_users: 0.6348; loss: 6.9952
2025-05-15 20:05:18 Test. Batch 2/5
2025-05-15 20:05:18 Test. loss_rec: 6.4210; loss_cl_pois: 2.9817; loss_cl_users: 0.5316; loss: 6.7723
2025-05-15 20:05:18 Test. Batch 3/5
2025-05-15 20:05:18 Test. loss_rec: 6.4812; loss_cl_pois: 2.9701; loss_cl_users: 0.5785; loss: 6.8361
2025-05-15 20:05:18 Test. Batch 4/5
2025-05-15 20:05:18 Test. loss_rec: 7.1392; loss_cl_pois: 2.9717; loss_cl_users: 0.0810; loss: 7.4445
2025-05-15 20:05:18 Testing finishes
2025-05-15 20:05:18 Testing loss: 6.9659627914428714
2025-05-15 20:05:18 Testing results:
2025-05-15 20:05:18 Recall@1: 0.2604
2025-05-15 20:05:18 NDCG@1: 0.2604
2025-05-15 20:05:18 Recall@5: 0.3699
2025-05-15 20:05:18 NDCG@5: 0.3171
2025-05-15 20:05:18 Recall@10: 0.4116
2025-05-15 20:05:18 NDCG@10: 0.3312
2025-05-15 20:05:18 Recall@20: 0.4246
2025-05-15 20:05:18 NDCG@20: 0.3345
2025-05-15 20:05:18 ==================================


2025-05-15 20:05:18 ================= Epoch 28/30 =================
2025-05-15 20:05:18 Train. Batch 0/5
2025-05-15 20:05:18 Train. loss_rec: 2.9084; loss_cl_pois: 2.4223; loss_cl_users: 0.8640; loss: 3.2370
2025-05-15 20:05:18 Train. Batch 1/5
2025-05-15 20:05:18 Train. loss_rec: 2.9128; loss_cl_pois: 2.4217; loss_cl_users: 1.0222; loss: 3.2572
2025-05-15 20:05:18 Train. Batch 2/5
2025-05-15 20:05:18 Train. loss_rec: 2.9069; loss_cl_pois: 2.4292; loss_cl_users: 0.9422; loss: 3.2440
2025-05-15 20:05:18 Train. Batch 3/5
2025-05-15 20:05:18 Train. loss_rec: 2.9087; loss_cl_pois: 2.4093; loss_cl_users: 0.9019; loss: 3.2398
2025-05-15 20:05:18 Train. Batch 4/5
2025-05-15 20:05:18 Train. loss_rec: 2.8855; loss_cl_pois: 2.3997; loss_cl_users: 0.1216; loss: 3.1377
2025-05-15 20:05:18 Training finishes at this epoch. It takes 0.005137948195139567 min
2025-05-15 20:05:18 Training loss: 3.2231
2025-05-15 20:05:18 Training Epoch 28/30 results:
2025-05-15 20:05:18 Recall@1: 1.0000
2025-05-15 20:05:18 NDCG@1: 1.0000
2025-05-15 20:05:18 Recall@5: 1.0000
2025-05-15 20:05:18 NDCG@5: 1.0000
2025-05-15 20:05:18 Recall@10: 1.0000
2025-05-15 20:05:18 NDCG@10: 1.0000
2025-05-15 20:05:18 Recall@20: 1.0000
2025-05-15 20:05:18 NDCG@20: 1.0000
2025-05-15 20:05:18 

2025-05-15 20:05:18 Testing
2025-05-15 20:05:18 Test. Batch 0/5
2025-05-15 20:05:18 Test. loss_rec: 6.3956; loss_cl_pois: 2.9708; loss_cl_users: 0.5602; loss: 6.7487
2025-05-15 20:05:18 Test. Batch 1/5
2025-05-15 20:05:18 Test. loss_rec: 6.6730; loss_cl_pois: 2.9713; loss_cl_users: 0.5637; loss: 7.0265
2025-05-15 20:05:18 Test. Batch 2/5
2025-05-15 20:05:19 Test. loss_rec: 6.4419; loss_cl_pois: 2.9685; loss_cl_users: 0.6013; loss: 6.7988
2025-05-15 20:05:19 Test. Batch 3/5
2025-05-15 20:05:19 Test. loss_rec: 6.5679; loss_cl_pois: 2.9644; loss_cl_users: 0.5490; loss: 6.9192
2025-05-15 20:05:19 Test. Batch 4/5
2025-05-15 20:05:19 Test. loss_rec: 6.2261; loss_cl_pois: 2.9630; loss_cl_users: 0.1124; loss: 6.5336
2025-05-15 20:05:19 Testing finishes
2025-05-15 20:05:19 Testing loss: 6.8053618431091305
2025-05-15 20:05:19 Testing results:
2025-05-15 20:05:19 Recall@1: 0.2749
2025-05-15 20:05:19 NDCG@1: 0.2749
2025-05-15 20:05:19 Recall@5: 0.3982
2025-05-15 20:05:19 NDCG@5: 0.3425
2025-05-15 20:05:19 Recall@10: 0.4262
2025-05-15 20:05:19 NDCG@10: 0.3517
2025-05-15 20:05:19 Recall@20: 0.4470
2025-05-15 20:05:19 NDCG@20: 0.3569
2025-05-15 20:05:19 ==================================


2025-05-15 20:05:19 ================= Epoch 29/30 =================
2025-05-15 20:05:19 Train. Batch 0/5
2025-05-15 20:05:19 Train. loss_rec: 2.8536; loss_cl_pois: 2.4084; loss_cl_users: 0.9300; loss: 3.1874
2025-05-15 20:05:19 Train. Batch 1/5
2025-05-15 20:05:19 Train. loss_rec: 2.8853; loss_cl_pois: 2.4186; loss_cl_users: 0.8557; loss: 3.2127
2025-05-15 20:05:19 Train. Batch 2/5
2025-05-15 20:05:19 Train. loss_rec: 2.8798; loss_cl_pois: 2.4060; loss_cl_users: 0.8449; loss: 3.2049
2025-05-15 20:05:19 Train. Batch 3/5
2025-05-15 20:05:19 Train. loss_rec: 2.8612; loss_cl_pois: 2.4125; loss_cl_users: 0.8133; loss: 3.1838
2025-05-15 20:05:19 Train. Batch 4/5
2025-05-15 20:05:19 Train. loss_rec: 2.8393; loss_cl_pois: 2.4149; loss_cl_users: 0.2638; loss: 3.1072
2025-05-15 20:05:19 Training finishes at this epoch. It takes 0.005142704645792643 min
2025-05-15 20:05:19 Training loss: 3.1792
2025-05-15 20:05:19 Training Epoch 29/30 results:
2025-05-15 20:05:19 Recall@1: 0.9941
2025-05-15 20:05:19 NDCG@1: 0.9941
2025-05-15 20:05:19 Recall@5: 1.0000
2025-05-15 20:05:19 NDCG@5: 0.9978
2025-05-15 20:05:19 Recall@10: 1.0000
2025-05-15 20:05:19 NDCG@10: 0.9978
2025-05-15 20:05:19 Recall@20: 1.0000
2025-05-15 20:05:19 NDCG@20: 0.9978
2025-05-15 20:05:19 

2025-05-15 20:05:19 Testing
2025-05-15 20:05:19 Test. Batch 0/5
2025-05-15 20:05:19 Test. loss_rec: 6.4223; loss_cl_pois: 2.9883; loss_cl_users: 0.6020; loss: 6.7814
2025-05-15 20:05:19 Test. Batch 1/5
2025-05-15 20:05:19 Test. loss_rec: 6.2685; loss_cl_pois: 2.9767; loss_cl_users: 0.6634; loss: 6.6325
2025-05-15 20:05:19 Test. Batch 2/5
2025-05-15 20:05:19 Test. loss_rec: 6.6911; loss_cl_pois: 2.9853; loss_cl_users: 0.5913; loss: 7.0487
2025-05-15 20:05:19 Test. Batch 3/5
2025-05-15 20:05:19 Test. loss_rec: 6.6828; loss_cl_pois: 2.9946; loss_cl_users: 0.5682; loss: 7.0391
2025-05-15 20:05:19 Test. Batch 4/5
2025-05-15 20:05:19 Test. loss_rec: 5.9254; loss_cl_pois: 2.9825; loss_cl_users: 0.1413; loss: 6.2378
2025-05-15 20:05:19 Testing finishes
2025-05-15 20:05:19 Testing loss: 6.747880363464356
2025-05-15 20:05:19 Testing results:
2025-05-15 20:05:19 Recall@1: 0.2975
2025-05-15 20:05:19 NDCG@1: 0.2975
2025-05-15 20:05:19 Recall@5: 0.4060
2025-05-15 20:05:19 NDCG@5: 0.3547
2025-05-15 20:05:19 Recall@10: 0.4429
2025-05-15 20:05:19 NDCG@10: 0.3667
2025-05-15 20:05:19 Recall@20: 0.4588
2025-05-15 20:05:19 NDCG@20: 0.3706
2025-05-15 20:05:19 ==================================


2025-05-15 20:05:19 6. Final Results
2025-05-15 20:05:19 {'Rec1': '0.2975', 'Rec5': '0.4179', 'Rec10': '0.4586', 'Rec20': '0.4755', 'NDCG1': '0.2975', 'NDCG5': '0.3575', 'NDCG10': '0.3682', 'NDCG20': '0.3715'}
2025-05-15 20:05:19 

